<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ARM常用指令(2)</title>
    <url>/2022/06/15/ARM%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-2/</url>
    <content><![CDATA[<!-- <meta name="referrer" content="no-referrer" /> -->
<h2 id="算术与移位指令">算术与移位指令</h2>
<h3 id="加减法指令">加减法指令</h3>
<ul>
<li>add指令</li>
</ul>
<ol type="1">
<li><p>立即数加法指令</p>
<p>ARM文档描述如下</p>
<blockquote>
<p>ADD <em>Wd|WSP</em>, <em>Wn|WSP</em>, #<em>imm</em>{, <em>shift</em>}
; 32-bit</p>
</blockquote>
<blockquote>
<p>ADD <em>Xd|SP</em>, <em>Xn|SP</em>, #<em>imm</em>{, <em>shift</em>} ;
64-bit</p>
</blockquote>
<p><span id="more"></span></p>
<p>这里要注意的是立即数的范围是0~4095，但是在实际过程中，写出这种语句编译运行也不会报错:
<span class="math inline">\(add \enspace x0, \enspace x0, \enspace
4096\)</span></p>
<p>使用汇编与反汇编来看看编译器如何处理的，具体的汇编反汇编命令，可以查看<a
href="https://www.huziliang.com/2022/05/12/ARM%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/">ARM常用指令（1）</a>
中MOV指令讲解。</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.<span class="built_in">arch</span> armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	3</span><br><span class="line"></span><br><span class="line">.global	test2</span><br><span class="line">test2:</span><br><span class="line"></span><br><span class="line">    add x0, x0, <span class="comment">#4095</span></span><br><span class="line">    add x2, x2, <span class="comment">#4096</span></span><br><span class="line"></span><br><span class="line">    ret</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">main.o:     file format elf64-littleaarch64</span><br><span class="line"></span><br><span class="line">Contents of section .text:</span><br><span class="line"> 0000 e10300aa 204040f8 220440f9 00fc3f91  .... @@.<span class="string">&quot;.@...?.</span></span><br><span class="line"><span class="string"> 0010 42044091 c0035fd6                    B.@..._.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Disassembly of section .text:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">0000000000000000 &lt;test2&gt;:</span></span><br><span class="line"><span class="string">   0:   aa0003e1        orr     x1, xzr, x0</span></span><br><span class="line"><span class="string">   4:   f8404020        ldur    x0, [x1,#4]</span></span><br><span class="line"><span class="string">   8:   f9400422        ldr     x2, [x1,#8]</span></span><br><span class="line"><span class="string">   c:   913ffc00        add     x0, x0, #0xfff</span></span><br><span class="line"><span class="string">  10:   91400442        add     x2, x2, #0x1, lsl #12</span></span><br><span class="line"><span class="string">  14:   d65f03c0        ret</span></span><br></pre></td></tr></table></figure></p>
<p>add x0, x0, #4095 实际上为 add x0, x0, #0xfff</p>
<p>add x2, x2, #4096 实际上为 add x2, x2, #0x1, lsl #12</p>
<p>但是如果写成 add x0, x0, #4097编译就会报错 immediate out of
range</p></li>
<li><p>寄存器加法指令</p>
<ul>
<li>加法指令</li>
</ul>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">add x0, x1, x2, UXTB</span><br><span class="line"><span class="comment">// 类似的extend还有UXTB, UXTH, UXTW, UXTX, SXTB, SXTH, SXTW or SXTX.</span></span><br></pre></td></tr></table></figure></p>
<p><img src="https://s2.loli.net/2022/05/23/tPV4XZDEi3wkaAU.png" /></p>
<p>UXT*：零扩展</p>
<p>SXT*：有符号扩展</p>
<p>例如：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mov x1, #<span class="number">1</span></span><br><span class="line">mov x2, #<span class="number">0x108a</span></span><br><span class="line">add x0, x1, x2, UXTB       <span class="comment">//(1)</span></span><br><span class="line">add x0, x1, x2, SXTB       <span class="comment">//(2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// (1)式结果为0x8B，UXTB取x2寄存器低字节8A做零扩展，与x1寄存器立即数1相加，结果为8B</span></span><br><span class="line"><span class="comment">// (2)式结果为0xFFFFFF8B，SXTB取x2寄存器低字节8A做有符号扩展，与x1寄存器立即数1相加，结果为FFFFFF8B</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>移位加法指令</li>
</ul>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">add x0, x1, x2, LSL <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>32bit寄存器移位操作数范围为0~31</p>
</blockquote>
<blockquote>
<p>64bit寄存器移位操作数范围为0~63</p>
</blockquote></li>
</ol>
<ul>
<li><p>减法指令</p>
<p>减法指令与加法指令类似，也分为立即数减法指令，寄存器减法指令。</p></li>
</ul>
<h3 id="cmp指令">cmp指令</h3>
<p>cmp指令内部调用subs指令实现</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cmp x1, x2</span><br><span class="line"></span><br><span class="line">=&gt;</span><br><span class="line"></span><br><span class="line">subs    xzr, x1, x2</span><br></pre></td></tr></table></figure>
<h3 id="移位指令">移位指令</h3>
<ul>
<li>LSL：逻辑左移，最高位丢弃，最低位补0</li>
<li>LSR：逻辑右移，最低位丢弃，最高位补0</li>
<li>ASR：算术右移，最高位符号扩展，最低位丢弃</li>
<li>ROR：循环右移，最低位移动到最高位</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr w1, =<span class="number">0x8000008a</span></span><br><span class="line"><span class="comment">// w1 二进制表示：0b10000000000000000000000010001010</span></span><br><span class="line"></span><br><span class="line">asr w2, w1, <span class="number">1</span></span><br><span class="line"><span class="comment">// 算术右移1位，高位按照有符号补充，低位丢弃</span></span><br><span class="line"><span class="comment">// w2 二进制表示：0b11000000000000000000000001000101，16进制表示为0xC0000045</span></span><br><span class="line"></span><br><span class="line">lsr w3, w1, <span class="number">1</span></span><br><span class="line"><span class="comment">// 逻辑右移1位，最低位丢弃，最高位补0</span></span><br><span class="line"><span class="comment">// w3 二进制表示为：0b01000000000000000000000001000101，16进制表示为0x40000045</span></span><br><span class="line"></span><br><span class="line">lsl w4, w1, <span class="number">1</span></span><br><span class="line"><span class="comment">// 逻辑左移1位，最高位丢弃，最低位补0</span></span><br><span class="line"><span class="comment">// w4 二进制表示为：0b00000000000000000000000100010100，16进制表示为0x114</span></span><br><span class="line"></span><br><span class="line">ror w5, w1, <span class="number">2</span></span><br><span class="line"><span class="comment">// 循环右移1位，最低位移动到最高位</span></span><br><span class="line"><span class="comment">// w4 二进制表示为：0b10100000000000000000000000100010，16进制表示为0xA0000022</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="位操作指令">位操作指令</h3>
<ul>
<li>与操作</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">and</span> x0, x1, x2  <span class="comment">// x1 = 6, x2 = 1 =&gt; x0 = 0</span></span><br><span class="line"></span><br><span class="line">ands x0, x1, x2 <span class="comment">// 影响pstate状态位，x1 = 6, x2 = 1 =&gt; x0 = 0</span></span><br><span class="line">mrs x0, nzcv <span class="comment">// x0 = 0x40000，表示z位置为1，说明ands置pstate中z位置为1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>或操作</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">orr x0, x1, x2  <span class="comment">// x1 = 6, x2 = 1 =&gt; x0 = 7</span></span><br></pre></td></tr></table></figure>
<ul>
<li>异或操作</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">eor x0, x1, x2  <span class="comment">// x1 = 4, x2 = 1 =&gt; x0 = 5</span></span><br></pre></td></tr></table></figure>
<p>异或操作真值表</p>
<table>
<thead>
<tr>
<th>0 ^ 0</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>0 ^ 1</td>
<td>1</td>
</tr>
<tr>
<td>1 ^ 0</td>
<td>1</td>
</tr>
<tr>
<td>1 ^ 1</td>
<td>0</td>
</tr>
</tbody>
</table>
<ol type="1">
<li>0异或任何数为任何数本身</li>
<li>1异或任何数为任何数取反</li>
<li>任何数异或自己为0</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 实现位翻转</span></span><br><span class="line"><span class="comment">// 翻转0b10100001，第2、3位</span></span><br><span class="line"><span class="number">10100001</span> ^ <span class="number">00000110</span> = <span class="number">10100111</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 交换两数</span></span><br><span class="line"><span class="comment">// 交换 a = 10100001和b = 00000110</span></span><br><span class="line">a = a^b <span class="comment">// a = 10100111</span></span><br><span class="line">b = b^a <span class="comment">// b = 10100001</span></span><br><span class="line">a = a^b <span class="comment">// a = 00000110</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 变量设置为0</span></span><br><span class="line">eor x1, x1</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. 判断变量相等</span></span><br><span class="line">(a ^ b) == <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ul>
<li>位清除</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 清除x0中第0、1和3位，保持其余的不变</span></span><br><span class="line">mov x0, #<span class="number">0x1111</span></span><br><span class="line">mov x1, #<span class="number">0x1011</span></span><br><span class="line">bic x0, x0, x1 <span class="comment">// x0 = 0x0100</span></span><br></pre></td></tr></table></figure>
<p>以下为三个目前用的不多的指令</p>
<ul>
<li>CLZ指令</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 统计最高位1之前还有几个0</span></span><br><span class="line">ldr x1, =<span class="number">0x1100000034578000</span> <span class="comment">// x1 二进制为：0b0001000100000000000000000000000000110100010101111000000000000000</span></span><br><span class="line">clz x0, x1</span><br><span class="line"><span class="comment">// x1 最高位为1是第60位，前面还有三个0，因此x0为3</span></span><br></pre></td></tr></table></figure>
<ul>
<li>BFI指令</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用作bit位插入</span></span><br><span class="line"></span><br><span class="line">mov x0, #<span class="number">0</span></span><br><span class="line">mov x1, #<span class="number">0x05</span></span><br><span class="line">bfi x0, x1, #<span class="number">4</span>, #<span class="number">4</span> <span class="comment">//将x0 BIT[4:4+(4-1)]替换为x1[0:0+(4-1)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际上BFI会被替换成BFM，上述语句等价于下：</span></span><br><span class="line">movz    x0, #<span class="number">0x0</span></span><br><span class="line">movz    x1, #<span class="number">0x5</span></span><br><span class="line">bfm     x0, x1, #<span class="number">60</span>, #<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 可用来将部分比特位清零</span></span><br><span class="line">bfi x0, XZR, #<span class="number">0</span>, #<span class="number">3</span></span><br></pre></td></tr></table></figure>
<ul>
<li>UBFX</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 位提取指令</span></span><br><span class="line"><span class="comment">// UBFX 提取后无符号扩展</span></span><br><span class="line"><span class="comment">// SBFX  提取后有符号扩展</span></span><br><span class="line"></span><br><span class="line">mov x1, <span class="number">0x8a</span>   <span class="comment">//  x1 : 10001010</span></span><br><span class="line">ubfx x0, x1, #<span class="number">4</span>, #<span class="number">4</span>   <span class="comment">// x0 : 00001000</span></span><br><span class="line">sbfx x0, x1, #<span class="number">4</span>, #<span class="number">4</span>   <span class="comment">// x0 : 11111000</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/23/TGHaNA9PEgOQj83.png" /></p>
]]></content>
      <tags>
        <tag>ARM</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title>ARM常用指令(3)</title>
    <url>/2022/07/27/ARM%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-3/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<style type="text/css" rel="stylesheet">
col{
    /* width: 0 !important; */
    max-width: 10% !important;
}
</style>
<h2 id="比较跳转指令">比较跳转指令</h2>
<h3 id="比较指令">比较指令</h3>
<ul>
<li>cmn指令</li>
</ul>
<p>与cmp指令类似，不同的是cmn指令是将一个数与另一个数的相反数进行比较，并且在汇编过程中等同于adds指令</p>
<span id="more"></span>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cmn x1, x2</span><br><span class="line">=&gt;</span><br><span class="line">adds xzr, x1, x2</span><br></pre></td></tr></table></figure>
<ul>
<li>csel指令</li>
</ul>
<blockquote>
<p>CSEL <em>Wd</em>, <em>Wn</em>, <em>Wm</em>, <em>cond</em> ;
32-bit</p>
</blockquote>
<blockquote>
<p>CSEL <em>Xd</em>, <em>Xn</em>, <em>Xm</em>, <em>cond</em> ;
64-bit</p>
</blockquote>
<p>判断cond是否为真，为真返回Xn/Wn，为假返回Xm/Wm，返回值存放于Xd/Wd寄存器</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mov x1, #<span class="number">3</span></span><br><span class="line">mov x2, #<span class="number">4</span></span><br><span class="line"></span><br><span class="line">cmp x1, x2</span><br><span class="line">csel x0, x1, x2, ge  <span class="comment">// x0 = 4</span></span><br></pre></td></tr></table></figure>
<ul>
<li>cset指令</li>
</ul>
<blockquote>
<p>CSET <em>Wd</em>, <em>cond</em> ; 32-bit</p>
</blockquote>
<blockquote>
<p>CSET <em>Xd</em>, <em>cond</em> ; 64-bit</p>
</blockquote>
<p>判断cond是否为真，为真设置Xd/Wd为1，否则设置为0</p>
<ul>
<li>csinc指令</li>
</ul>
<p>类似于csel，不过当cond为假是，返回Xm/Wm + 1</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mov x1, #<span class="number">3</span></span><br><span class="line">mov x2, #<span class="number">4</span></span><br><span class="line"></span><br><span class="line">cmp x1, x2</span><br><span class="line">csinc x0, x1, x2, ge <span class="comment">// x0 = 5</span></span><br></pre></td></tr></table></figure>
<h3 id="跳转指令">跳转指令</h3>
<ul>
<li><p>普通跳转指令</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th>B</th>
<th>B label 当前PC偏移量±128MB范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>B.cond</td>
<td>B.cond label 当前PC偏移量±1MB范围</td>
</tr>
<tr>
<td>BL</td>
<td>BL label
将返回值保存至X30寄存器，保存的值等于调用BL指令的当前PC值加4</td>
</tr>
<tr>
<td>BR</td>
<td>BR Xn 跳转到寄存器指定地址</td>
</tr>
<tr>
<td>BLR</td>
<td>BLR Xn 跳转到寄存器指定地址，并将返回地址保存在X30寄存器</td>
</tr>
</tbody>
</table></li>
<li><p>比较跳转指令</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th>CBZ</th>
<th>cbz Xt, label Xt == 0，跳转至label，跳转范围是当前PC地址±1MB</th>
</tr>
</thead>
<tbody>
<tr>
<td>CBNZ</td>
<td>cbnz Xt, label Xt != 0，跳转至label，跳转范围是当前PC地址±1MB</td>
</tr>
<tr>
<td>TBZ</td>
<td>tbz R<t>, #imm, label
Rt寄存器第imm位为0，跳转至label，跳转范围是当前PC地址±32KB</td>
</tr>
<tr>
<td>TBNZ</td>
<td>tbnz R<t>, #imm, label
Rt寄存器第imm位不为0，跳转至label，跳转范围是当前PC地址±32KB</td>
</tr>
</tbody>
</table></li>
<li><p>X29和X30寄存器的使用</p>
<p>调用子函数时，需要将X29和X30寄存器入栈，在主函数返回时，将X29和X30出栈，否则会出现主函数无法退出的情况。</p>
<p>错误案例：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">test2</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">test2</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// main.s</span></span><br><span class="line">.arch armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	<span class="number">3</span></span><br><span class="line"></span><br><span class="line">.global csel_test</span><br><span class="line">csel_test:</span><br><span class="line">    cmp x0, <span class="number">0</span></span><br><span class="line">    sub x2, x1, <span class="number">1</span></span><br><span class="line">    add x3, x1, <span class="number">2</span></span><br><span class="line">    csel x0, x3, x2, eq</span><br><span class="line">    ret</span><br><span class="line"></span><br><span class="line">.global	test2</span><br><span class="line">test2:</span><br><span class="line">    mov x0, <span class="number">1</span></span><br><span class="line">    mov x2, <span class="number">3</span></span><br><span class="line">    bl csel_test</span><br><span class="line">    ret</span><br></pre></td></tr></table></figure></p>
<p>Linux主机编译支持debug的arm跨平台可执行文件方法，参照另一篇文章《Android
Toolchain编译与GDB调试》</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./gdb <span class="comment"># 进入gdb程序</span></span><br><span class="line">b main <span class="comment"># 加断点</span></span><br><span class="line">n <span class="comment"># next 下一步，不进入函数 执行至test2();</span></span><br><span class="line">s <span class="comment"># step 下一步，进入test2函数内部</span></span><br><span class="line">n</span><br><span class="line">n</span><br><span class="line">info r <span class="comment"># info register 打印寄存器，可以查看lr寄存器为0x4030f0，pc寄存器为0x4031ac</span></span><br><span class="line">s <span class="comment"># step 下一步，进入csel_test函数内部</span></span><br><span class="line">info r <span class="comment"># info register 打印寄存器，可以查看lr寄存器为0x4031b0，pc寄存器为0x403190</span></span><br></pre></td></tr></table></figure></p>
<p>以上过程可以看出，lr寄存器的值，在csel_test子函数执行时lr寄存器的值为上一步pc寄存器值+4，即0x4031ac
+ 4 = 0x4031b0</p>
<p>当csel_test函数返回值test2时，lr寄存器的值为0x4031ac，此时test2函数只有按在lr寄存器的值为0x4030f0时才能正确返回，因此函数会卡住</p>
<p>正确案例：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">.arch armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	<span class="number">3</span></span><br><span class="line"></span><br><span class="line">.global csel_test</span><br><span class="line">csel_test:</span><br><span class="line">    cmp x0, <span class="number">0</span></span><br><span class="line">    sub x2, x1, <span class="number">1</span></span><br><span class="line">    add x3, x1, <span class="number">2</span></span><br><span class="line">    csel x0, x3, x2, eq</span><br><span class="line">    ret</span><br><span class="line"></span><br><span class="line">.global	main</span><br><span class="line">main:</span><br><span class="line">		stp x29, x30, [sp, <span class="number">-16</span>]!</span><br><span class="line">    mov x0, <span class="number">1</span></span><br><span class="line">    mov x2, <span class="number">3</span></span><br><span class="line">		ldp x29, x30, [sp], #<span class="number">16</span></span><br><span class="line">    bl csel_test</span><br><span class="line">    ret</span><br></pre></td></tr></table></figure></p>
<p>重复上述gdb步骤，查看lr，pc寄存器的值</p>
<p>test2，lr寄存器的值为0x4030f0，pc寄存器的值为0x4031b0</p>
<p>csel_test，lr寄存器的值为0x4031b4，pc寄存器的值为0x4031a0</p>
<p>返回test2函数后，lr寄存器的值为0x4030f0，pc寄存器的值为0x4031b8</p>
<p>test2调用子函数前后lr寄存器的值保持不变，test2函数正常结束</p></li>
</ul>
<h3 id="pc相对地址加载指令">PC相对地址加载指令</h3>
<ul>
<li>ADR指令</li>
</ul>
<p>加载当前PC值±1MB范围内的label地址到目的寄存器</p>
<ul>
<li>ADRP指令</li>
</ul>
<p>加载当前PC值±4GB范围内的label 4KB对齐的地址到目的寄存器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.<span class="built_in">arch</span> armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	3</span><br><span class="line"></span><br><span class="line">my_data1:</span><br><span class="line"> .dword 0x8a</span><br><span class="line"></span><br><span class="line">.global	test2</span><br><span class="line">test2:</span><br><span class="line">    adr x0, my_data1</span><br><span class="line">    ldr x1, [x0]</span><br><span class="line"></span><br><span class="line">    adrp x2, my_data1</span><br><span class="line">    ldr x3, [x2]</span><br><span class="line">    ret</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以通过gdb -tui进行界面模式，然后通过layout
reg切换至寄存器显示模式</p>
</blockquote>
<p>通过GDB查看，x0地址为0x403190，x2地址为0x403000，前者为my_data1的地址，否则为my_data1地址按照4KB对齐后的地址，因此x1寄存器的值为0x8a，与定义相同，x3寄存器的值错误。</p>
<figure>
<img src="https://s2.loli.net/2022/05/23/4w1xtTYNIyQXb7J.png"
alt="https://s2.loli.net/2022/05/23/4w1xtTYNIyQXb7J.png" />
<figcaption
aria-hidden="true">https://s2.loli.net/2022/05/23/4w1xtTYNIyQXb7J.png</figcaption>
</figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adrp x2, my_data1</span><br><span class="line">add x2, x2, <span class="comment">#:lo12:my_data1</span></span><br><span class="line">ldr x3, [x2]</span><br></pre></td></tr></table></figure>
<p>“#:lo12:”，表示4KB大小的偏移量，再通过GDB查看，结果正确。</p>
<figure>
<img src="https://s2.loli.net/2022/05/23/CxqeDOmPaLQ4hgN.png"
alt="https://s2.loli.net/2022/05/23/CxqeDOmPaLQ4hgN.png" />
<figcaption
aria-hidden="true">https://s2.loli.net/2022/05/23/CxqeDOmPaLQ4hgN.png</figcaption>
</figure>
<ul>
<li>adr和ldr伪指令的区别
<ol type="1">
<li>ldr伪指令加载的是绝对地址，adr加载的是当前pc的相对地址</li>
<li>当运行地址和链接地址相同时，adr和ldr伪指令等效</li>
<li>当运行地址和链接地址不同时，ldr伪指令加载label的链接地址，adr加载label物理地址</li>
</ol></li>
</ul>
<h3 id="系统寄存器访问指令">系统寄存器访问指令</h3>
<ul>
<li>mrs指令</li>
</ul>
<p>读取系统寄存器的值到通用寄存器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mrs x0, nzcv</span><br><span class="line">// 读取NZCV寄存器，查看标志位是否为1</span><br></pre></td></tr></table></figure>
<ul>
<li>msr指令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mrs x0, nzcv</span><br><span class="line">// 更新NZCV寄存器的值</span><br></pre></td></tr></table></figure>
<h3 id="内存屏障指令">内存屏障指令</h3>
<table>
<thead>
<tr class="header">
<th>
DMB
</th>
<th>
数据存储屏障，Data Memory
Barrier，确保在执行新的存储器访问前所有的存储器访问都已经完成
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
DSB
</td>
<td>
数据同步屏障，Data Synchronization
Barrier，确保在下一个指令执行前所有的存储器访问都已经完成
</td>
</tr>
<tr class="even">
<td>
ISB
</td>
<td>
指令同步屏障，Instruction Synchronization
Barrier，清空流水线，确保在执行新的指令前，之前所有的指令都已经完成
</td>
</tr>
<tr class="odd">
<td>
LDAR
</td>
<td>
加载-获取指令，Load-acquire，LDAR指令后面的读写内存指令必须在LDAR指令之后才能完成
</td>
</tr>
<tr class="even">
<td>
STLR
</td>
<td>
存储-释放指令，Store-release，所有加载和存储指令必须在STLR指令之前完成
</td>
</tr>
</tbody>
</table>
<h3 id="伪指令">伪指令</h3>
<ul>
<li><p>对齐伪指令</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">.align <span class="number">2</span>  # 四字节对齐</span><br><span class="line">.align <span class="number">5</span>, <span class="number">0</span>, <span class="number">100</span>  # <span class="number">32</span>字节对齐，最多跳过字节数为<span class="number">100</span>，填充<span class="number">0</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>数据定义伪指令</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">.byte	          将<span class="number">8</span>位数作为数据插入汇编代码</span><br><span class="line">.hword/.<span class="type">short</span>	  将<span class="number">16</span>位数作为数据插入汇编代码</span><br><span class="line">.<span class="type">long</span>/.<span class="type">int</span>	    将<span class="number">32</span>位数作为数据插入汇编代码</span><br><span class="line">.word	          将<span class="number">32</span>位数作为数据插入汇编代码</span><br><span class="line">.quad	          将<span class="number">64</span>位数作为数据插入汇编代码</span><br><span class="line">.<span class="type">float</span>	        将浮点数作为数据插入汇编代码</span><br><span class="line">.ascii/.string	将字符串作为数据插入汇编代码</span><br><span class="line">.asciz	        将字符串作为数据插入汇编代码，自动插入结尾字符”\<span class="number">0</span>”</span><br><span class="line">.rept/.endr   	重复执行操作</span><br><span class="line">  .rept <span class="number">3</span></span><br><span class="line">  .<span class="type">long</span> <span class="number">0</span></span><br><span class="line">  .endr</span><br><span class="line">.equ	          符号赋值操作</span><br><span class="line">	.equ my_data, <span class="number">100</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>函数相关伪指令</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">.global                 全局函数符号，或者全局变量符号</span><br><span class="line">.include                引用头文件</span><br><span class="line">.<span class="keyword">if</span> .<span class="keyword">else</span> .endif        条件判断</span><br><span class="line">.ifdef/.ifndef symbol   判断符号是否定义</span><br><span class="line">.ifc/.ifeqs             判断两字符串是否相等</span><br><span class="line">.ifeq/.ifge/.ifle/.ifne 判断值是否为<span class="number">0</span>/大于等于/小于等于<span class="number">0</span>/不等于<span class="number">0</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>宏伪指令</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">.macro add p1 p2</span><br><span class="line">add x0, \p1, \p2</span><br><span class="line">.endm</span><br></pre></td></tr></table></figure></p></li>
</ul>
]]></content>
      <tags>
        <tag>ARM</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title>ARM常用指令(1)</title>
    <url>/2022/05/12/ARM%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<h2 id="加载与存储指令">加载与存储指令</h2>
<h3 id="基于基地址的寻址模式">基于基地址的寻址模式</h3>
<ul>
<li>基地址寻址</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, [x1]</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<ul>
<li>基地址偏移量寻址</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, [x1, #<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>基地址扩张寻址</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, [x1, x2]</span><br><span class="line">ldr x0, [x1, x2, LSL #<span class="number">3</span>]</span><br><span class="line">ldr x0, [x1, x2, UXTW]</span><br><span class="line">ldr x0, [x1, w2, UXTW #<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>UXTW表示从寄存器中提取32位数据，高位补0，无符号数。相同的extend还包括UXTB，UXTH。</p>
<p>SXTW表示从寄存器中提取32位数据，高位补0，有符号数。相同的extend还包括SXTB，SXTH。</p>
<h3 id="变基寻址模式">变基寻址模式</h3>
<ul>
<li>前变基模式</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, [x1, #<span class="number">4</span>]!</span><br></pre></td></tr></table></figure>
<ul>
<li>后变基模式</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, [x1], #<span class="number">4</span></span><br></pre></td></tr></table></figure>
<h3 id="ldr伪指令">LDR伪指令</h3>
<p>ldr既可以是普通的加载指令，也可以在第二个参数前加上“=”后，表示大范围加载地址的伪指令。注：无str伪指令</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldr x0, =label <span class="comment">// 此时x0中即为label的值</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>‘[]’方括号表示从括号中参数的内存地址中读取或者存储数据，‘!’感叹号表示更新存放地址的寄存器，也即写回和更新寄存器</p>
</blockquote>
<h3 id="ldr和str的变种">ldr和str的变种</h3>
<table>
<thead>
<tr>
<th>指令</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>ldr</td>
<td>普通数据加载指令，4字节与8字节数据，以W或者X寄存器区分</td>
</tr>
<tr>
<td>ldrsw</td>
<td>有符号数据加载指令，word</td>
</tr>
<tr>
<td>ldrb</td>
<td>数据加载指令，byte</td>
</tr>
<tr>
<td>ldrsb</td>
<td>有符号数据加载指令，byte</td>
</tr>
<tr>
<td>ldrh</td>
<td>数据加载指令，half-word</td>
</tr>
<tr>
<td>ldrsh</td>
<td>有符号数据加载指令，half-word</td>
</tr>
<tr>
<td>strb</td>
<td>数据存储指令，byte</td>
</tr>
<tr>
<td>strh</td>
<td>数据存储指令，halfword</td>
</tr>
</tbody>
</table>
<h3 id="多字节加载与存储指令">多字节加载与存储指令</h3>
<p>在A32中通常使用LDM，STM指令实现多字节内存加载和存储，但是在A64架构中取消了LDM和STM指令，取而代之的是LDP(Load
Pair)和STP(Store
Pair)指令。LDP和STP支持基地址偏移量寻址、前变基模式和后变基模式三种寻址方式。</p>
<ol type="1">
<li><p>基地址偏移量寻址</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldp x0, x1, [x2]</span><br><span class="line">stp x0, x1, [x2]</span><br></pre></td></tr></table></figure></p></li>
<li><p>前变基寻址</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldp x0, x1, [x2, #<span class="number">4</span>]！</span><br><span class="line">stp x0, x1, [x2]</span><br></pre></td></tr></table></figure></p></li>
<li><p>后编辑寻址</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ldp x0, x1, [x2], #<span class="number">4</span></span><br><span class="line">stp x0, x1, [x2], #<span class="number">4</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 以上常用指令简易测试汇编代码如下</span></span><br><span class="line">.arch armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	<span class="number">3</span></span><br><span class="line"></span><br><span class="line">my_data:</span><br><span class="line">    .word <span class="number">0x40</span></span><br><span class="line"></span><br><span class="line">.equ MY_LABEL, <span class="number">0x20</span></span><br><span class="line"></span><br><span class="line">.global	test2</span><br><span class="line">test2:</span><br><span class="line"></span><br><span class="line">    <span class="comment">// int a[10]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10&#125;;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// x1保存了数组首地址</span></span><br><span class="line">    mov x1, x0</span><br><span class="line">    <span class="comment">// 立即数</span></span><br><span class="line">    mov x3, #<span class="number">1</span></span><br><span class="line">    mov w4, #<span class="number">1</span></span><br><span class="line">    mov w5, #<span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 基地址模式</span></span><br><span class="line">    ldr x0, [x1] <span class="comment">//x0 = 1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 基地址+偏移量模式</span></span><br><span class="line">    ldr x0, [x1, #<span class="number">4</span>] <span class="comment">// x0 = 2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 基地址扩展模式</span></span><br><span class="line">    ldr x0, [x1, x3, lsl #<span class="number">3</span>] <span class="comment">// x0 = 3</span></span><br><span class="line">    ldr x0, [x1, w5, SXTW] <span class="comment">// x0 = 2</span></span><br><span class="line">    ldr x0, [x1, w4, SXTW #<span class="number">3</span>] <span class="comment">// x0 = 3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 变基模式</span></span><br><span class="line">    ldr x0, [x1, #<span class="number">4</span>]! <span class="comment">// 前变基模式 x0 = 2</span></span><br><span class="line">    ldr x0, [x1] <span class="comment">// 前变基模式后x1自动加4 此时x0 = 2</span></span><br><span class="line">    ldr x0, [x1], #<span class="number">4</span> <span class="comment">// 后变基模式 x0 = 2,</span></span><br><span class="line">    ldr x0, [x1] <span class="comment">// x0 = 3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 基地址寻址</span></span><br><span class="line">    ldp w6, w7, [x1, #<span class="number">4</span>]!</span><br><span class="line">    mov w0, w6 <span class="comment">// w0 = 6</span></span><br><span class="line">    mov w0, w7 <span class="comment">// w0 = 7</span></span><br><span class="line">    ret</span><br></pre></td></tr></table></figure>
<h3 id="入栈与出栈">入栈与出栈</h3>
<p>在程序中栈通常有以下用途：</p>
<ul>
<li>临时存储数据，如临时变量等</li>
<li>传递参数。ArmV8平台，如果函数参数不超过8个，那么将使用x0~x7通用寄存器传递参数，当传递参数超过8个时，就需要用到栈了。</li>
</ul>
<p>一般情况，栈是从高地址向低地址生长的数据结构，起始地址称为栈底，最后一个入栈元素地址称之为栈顶，指向栈顶的指针称之为栈指针，SP(Stack
Point)。</p>
<p>A32提供了push和pop指令进行入栈出栈操作，在A64指令集中移除了push和pop，使用ldp和stp取代。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">.arch armv8-a</span><br><span class="line">.text</span><br><span class="line">.align	<span class="number">3</span></span><br><span class="line"></span><br><span class="line">.global	test2</span><br><span class="line">test2:</span><br><span class="line"></span><br><span class="line">    mov x1, x0</span><br><span class="line">    ldp x2, x3, [x1] <span class="comment">// x2 = 1, x3 = 2</span></span><br><span class="line">		<span class="comment">// 栈向下扩展16字节</span></span><br><span class="line">    stp x2, x3, [sp, #<span class="number">-16</span>]!</span><br><span class="line">		<span class="comment">// 出栈，并使用后变基恢复sp位置</span></span><br><span class="line">    ldp x2, x3, [sp], #<span class="number">16</span></span><br><span class="line"></span><br><span class="line">    mov x0, x3 <span class="comment">// x2 = 1, x3 = 2</span></span><br><span class="line"></span><br><span class="line">    ret</span><br></pre></td></tr></table></figure>
<h3 id="mov指令">MOV指令</h3>
<p>mov指令通常用于寄存器之间的搬移和立即数搬移。</p>
<p>而能搬运的立即数只有以下两种：</p>
<ol type="1">
<li>16位立即数</li>
<li>16位立即数左移16位、32位或者48位的立即数</li>
</ol>
<p>此时mov指令等同于movz指令</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">movz x0, <span class="number">0x12bc</span>, LSL #<span class="number">16</span></span><br></pre></td></tr></table></figure>
<p>mov指令还可以用来搬运bitmask，此时等同orr指令</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">orr x0, XZR, #<span class="number">0xffff0000ffff</span></span><br></pre></td></tr></table></figure>
<p>可以通过反汇编验证以上结论：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">main.s:</span><br><span class="line"></span><br><span class="line">.arch armv8-a</span><br><span class="line">.text</span><br><span class="line">.align    <span class="number">3</span></span><br><span class="line"></span><br><span class="line">.global    test2</span><br><span class="line">test2:</span><br><span class="line">	mov x0, <span class="number">0x12bc0000</span></span><br><span class="line">	mov x1, <span class="number">0xffff0000ffff</span></span><br><span class="line">	ret</span><br></pre></td></tr></table></figure>
<blockquote>
<p>通常一个cpp文件要变成熟悉的可执行文件a.out，需要经过以下四个步骤</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/05/23/TuZB4nx3HyjrA9F.png" /></p>
<p>调用aarch64-linux-android-g++对main.s进行汇编过程：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">aarch64-linux-android-g++ -c main.s -o main.o</span><br></pre></td></tr></table></figure>
<p>调用aarch64-linux-android-objdump -s -d -M no-aliases
test.o对main.o进行反汇编</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">aarch64-linux-android-objdump -s -d -M no-aliases main.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># shell会打印出反汇编结果：</span></span><br><span class="line">main.o:     file format elf64-littleaarch64</span><br><span class="line"></span><br><span class="line">Contents of section .text:</span><br><span class="line"> 0000 8057a2d2 e13f00b2 c0035fd6 1f2003d5  .W...?...._.. ..</span><br><span class="line"></span><br><span class="line">Disassembly of section .text:</span><br><span class="line"></span><br><span class="line">0000000000000000 &lt;test2&gt;:</span><br><span class="line">   0:	d2a25780 	movz	x0, <span class="comment">#0x12bc, lsl #16</span></span><br><span class="line">   4:	b2003fe1 	orr	x1, xzr, <span class="comment">#0xffff0000ffff</span></span><br><span class="line">   8:	d65f03c0 	ret</span><br><span class="line">   c:	d503201f 	hint	<span class="comment">#0x0</span></span><br></pre></td></tr></table></figure>
<p>可以看到mov指令变成了movz和orr指令</p>
]]></content>
      <tags>
        <tag>ARM</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title>Android Toolchain编译与GDB调试</title>
    <url>/2022/08/26/Android-Toolchain%E7%BC%96%E8%AF%91%E4%B8%8EGDB%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>在进行linux主机上进行arm跨平台进行pure c++开发时，可能混有Neon
intrinsic或者ARM
assembly代码，此时进行代码编译和调试，可以使用standalone
toolchain进行编译，使用gdb+gdbserver进行调试。</p>
<span id="more"></span>
<p>首先需要在NDK
website上下载一个NDK工具包并解压，本人使用的是r14b版本，链接：<a
href="https://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip">https://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip</a></p>
<ul>
<li><p>Standalone Toolchain的编译</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> android-ndk-r14b/build/tools/</span><br><span class="line">./make-standalone-toolchain.sh --platform=android-21 --install-dir=./android-aarch64 --<span class="built_in">arch</span>=arm64</span><br><span class="line">./make-standalone-toolchain.sh --platform=android-21 --install-dir=./android-armv7 --<span class="built_in">arch</span>=arm</span><br></pre></td></tr></table></figure></p>
<p>通过以上命令，会生成android-aarch64，android-armv7两个目录，可以将生成的standalone
toolchain拷贝至固定目录</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r android-ndk-r14b/build/tools/android-aarch64 /opt</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r android-ndk-r14b/build/tools/android-armv7 /opt</span><br></pre></td></tr></table></figure></p>
<p>以上完成standalone toolchain生成</p></li>
<li><p>Linux主机编译arm跨平台pure c++程序</p>
<ol type="1">
<li>在Linux主机上准备main.cpp源代码文件</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">		std::cout &lt;&lt; <span class="string">&quot;hello world&quot;</span> &lt;&lt; <span class="string">std::endl;</span></span><br><span class="line"><span class="string">    return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>编写CMakeLists.txt文件</li>
</ol>
<p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.17)</span><br><span class="line"></span><br><span class="line">project(ARM)</span><br><span class="line"></span><br><span class="line">enable_language(ASM)</span><br><span class="line"></span><br><span class="line">set(CMAKE_CXX_STANDARD 11)</span><br><span class="line">set(CMAKE_CXX_STANDARD_REQUIRED ON)</span><br><span class="line">add_definitions(-w)</span><br><span class="line">SET(CMAKE_BUILD_TYPE <span class="string">&quot;Debug&quot;</span>)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG <span class="string">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;</span>)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE <span class="string">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)</span><br><span class="line"></span><br><span class="line">set(TARGET_CPU aarch64)</span><br><span class="line"></span><br><span class="line">set(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -static -fPIE -flax-vector-conversions&quot;</span>)</span><br><span class="line">if(TARGET_CPU STREQUAL <span class="string">&quot;aarch64&quot;</span>)</span><br><span class="line">    include_directories(/opt/android-ndk-r14b/android-aarch64/lib64/clang/7.0.2/<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line">    set(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -mfloat-abi=softfp -mfpu=neon&quot;</span>)</span><br><span class="line">    include_directories(/opt/android-ndk-r14b/android-armv7/lib64/clang/7.0.2/<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line">set(SOURCES</span><br><span class="line">    main.cpp</span><br><span class="line">    <span class="comment"># main.s</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">add_executable(main $&#123;SOURCES&#125;)</span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>编译ARM平台可执行文件</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CXX_COMPILER=/opt/android-ndk-r14b/android-aarch64/bin/aarch64-linux-android-g++</span><br><span class="line">CC_COMPILER=/opt/android-ndk-r14b/android-aarch64/bin/aarch64-linux-android-gcc</span><br><span class="line"><span class="built_in">cd</span> cmake-build-debug</span><br><span class="line">cmake .. -DCMAKE_C_COMPILER=<span class="variable">$CC_COMPILER</span> -DCMAKE_CXX_COMPILER=<span class="variable">$CXX_COMPILER</span></span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>ARM平台程序的执行</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adb push main /data/local/tmp</span><br><span class="line">adb shell ./data/local/tmp/main</span><br></pre></td></tr></table></figure></p></li>
<li><p>GDB+GDBServer调试</p>
<ol type="1">
<li>准备GDBServer</li>
</ol>
<p>测试手机一般出厂不会自带gdbserver，可以将NDK工具包中对应平台gdbserver推入手机</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adb push android-ndk-r14b/prebuilt/android-arm64/gdbserver/gdbserver /data/local/tmp</span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>启动GDBServer</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adb shell <span class="comment"># 进入手机shell命令行</span></span><br><span class="line"><span class="built_in">cd</span> /data/local/tmp</span><br><span class="line">./gdbserver tcp:9090 main</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正常输出如下：</span></span><br><span class="line">Process main created; pid = 7201</span><br><span class="line">gdbserver: Unable to determine the number of hardware watchpoints available.</span><br><span class="line">gdbserver: Unable to determine the number of hardware breakpoints available.</span><br><span class="line">Listening on port 9090</span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>在主机平台启动gdb调试程序</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> android-ndk-r14b/prebuilt/linux-x86_64/bin <span class="comment"># 进入ndk gdb程序目录</span></span><br><span class="line">adb forward tcp:9090 tcp:9090 <span class="comment"># 端口转发</span></span><br><span class="line">./gdb <span class="comment"># 进入gdb程序</span></span><br><span class="line">target remote localhost:9090 <span class="comment"># 开始获取信息并开始调试</span></span><br><span class="line">b main <span class="comment"># 设置断点</span></span><br><span class="line"><span class="comment"># 后续与普通GDB调试相同</span></span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">n  <span class="comment"># 下一步，不进入函数内部</span></span><br><span class="line">s  <span class="comment"># 下一步，进入函数内部</span></span><br><span class="line">l  <span class="comment"># 代码列表</span></span><br><span class="line">info r    <span class="comment"># 查看寄存器</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
]]></content>
      <tags>
        <tag>Android</tag>
        <tag>Toolchain</tag>
        <tag>GDB</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA原子操作</title>
    <url>/2022/08/08/CUDA%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<ol type="1">
<li><p>atomicAdd(dst, src)：*dst += src</p></li>
<li><p>atomicSub(dst, src)：*dst -= src</p></li>
<li><p>atomicOr(dst, src)：*dst |= src</p></li>
</ol>
<span id="more"></span>
<ol start="4" type="1">
<li><p>atomicAnd(dst, src)：*dst &amp;= src</p></li>
<li><p>atomicXor(dst, src)：*dst ^= src</p></li>
<li><p>atomicMax(dst, src)：<em>dst = std::max(</em>dst, src)</p></li>
<li><p>atomicMin(dst, src)：<em>dst = std::min(</em>dst, src)</p></li>
</ol>
<p>以上原子操作均会返回旧值。</p>
<ol type="1">
<li><p>old = atomicExch(dst, src) ：old = <em>dst; </em>dst = src;
不返回旧值，对标std::atomic的exchange函数</p></li>
<li><p>atomicCAS：判断是否相等，相等则写入，并读取旧值</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">old = <span class="built_in">atomicCAS</span>(dst, cmp, src)</span><br><span class="line"></span><br><span class="line">Like below:</span><br><span class="line"></span><br><span class="line">old = *dst;</span><br><span class="line"><span class="keyword">if</span> (old == cmp)</span><br><span class="line">  *dst = src;</span><br></pre></td></tr></table></figure></p>
<p>通过atomicCAS可以实现一些CUDA并未原生提供的原子操作，例如：读-修改-写回，乘</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">old = <span class="built_in">atomicCAS</span>(dst, expect, expect + src);</span><br><span class="line"></span><br><span class="line">old = <span class="built_in">atomicCAS</span>(dst, expect, expect * src);</span><br></pre></td></tr></table></figure></p></li>
</ol>
]]></content>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS平台设置定时运行的任务记录</title>
    <url>/2023/10/20/MacOS%E5%B9%B3%E5%8F%B0%E8%AE%BE%E7%BD%AE%E5%AE%9A%E6%97%B6%E8%BF%90%E8%A1%8C%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>最近考虑到iCloud的速度较慢，且偶尔会出现问题时，放弃iCloud，而是转而使用坚果云来进行多台主机之间的数据同步。</p>
<span id="more"></span>
<p>坚果云同步是会遇到一些隐藏文件无法同步的问题,
但是我也不需要同步这些隐藏文件, 包括恼人的 <code>.DS_Store</code> 文件,
因此我需要一个定时任务来定期清理这些文件。在 macOS 平台上，传统的
crontab 命令确实不太实用，因为 macOS 已经采用了 launchd
作为任务管理器。launchd
提供了更强大和灵活的方式来管理计划任务，允许你以更直观的方式创建和管理定时任务。</p>
<p>在 macOS 平台上，使用 <code>launchd</code>
来设置定时运行的任务。<code>launchd</code>
是一个系统级的守护程序，用于管理和监控各种系统和用户级任务。以下是如何使用
<code>launchd</code> 在 macOS 上设置定时运行的任务的步骤：</p>
<ol type="1">
<li><p>创建一个属性列表（plist）文件：</p>
<p>使用文本编辑器创建一个属性列表文件，该文件包含有关你的任务的描述，包括任务的类型、触发器和执行内容。属性列表文件的文件扩展名应为
<code>.plist</code>。</p>
<p>你可以使用以下示例属性列表作为参考，并根据你的需求进行修改：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">plist</span> <span class="keyword">PUBLIC</span> <span class="string">&quot;-//Apple//DTD PLIST 1.0//EN&quot;</span> <span class="string">&quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plist</span> <span class="attr">version</span>=<span class="string">&quot;1.0&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dict</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Label<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span>&gt;</span>com.vix.cron<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>ProgramArguments<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">array</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span>&gt;</span>这里存放需要执行的脚本地址<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">array</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Nice<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>StartInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>30<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>RunAtLoad<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">true</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>StandardErrorPath<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span>&gt;</span>/tmp/test.err<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>StandardOutPath<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span>&gt;</span>/tmp/test.out<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dict</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plist</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这个示例会每30秒执行一次脚本文件
<code>/path/to/your/script.sh</code>。</p>
<p>我的定时清理 <code>.DS_Store</code> 文件脚本参考如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">find ~/Documents -name &quot;.DS_Store&quot; -depth -exec rm -rf &#123;&#125; \;</span><br><span class="line">find ~/Desktop -name &quot;.DS_Store&quot; -depth -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure></li>
<li><p>将 plist 文件保存到适当的位置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/Library/LaunchAgents/</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/Library/LaunchDaemons/</span><br></pre></td></tr></table></figure>
<p>如果你想为当前用户设置任务，将 plist 文件保存到
<code>~/Library/LaunchAgents/</code>；如果你想为系统设置任务，将 plist
文件保存到 <code>/Library/LaunchDaemons/</code>。</p></li>
<li><p>加载任务：</p>
<p>使用以下命令加载你的任务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">launchctl load /path/to/your/plist/file.plist</span><br></pre></td></tr></table></figure>
<p>如果你将 plist 文件保存到
<code>~/Library/LaunchAgents/</code>，则使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">launchctl load ~/Library/LaunchAgents/yourfile.plist</span><br></pre></td></tr></table></figure>
<p>如果你将 plist 文件保存到
<code>/Library/LaunchDaemons/</code>，则使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo launchctl load /Library/LaunchDaemons/yourfile.plist</span><br></pre></td></tr></table></figure></li>
<li><p>启动或重新启动任务：</p>
<p>任务会根据属性列表中定义的时间触发。你还可以使用
<code>launchctl</code> 命令手动启动或重新启动任务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">launchctl start com.example.myjob</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo launchctl start com.example.myjob</span><br></pre></td></tr></table></figure>
<p>请替换 <code>com.example.myjob</code> 为你的任务的 Label
值。</p></li>
<li><p>停止任务：</p>
<p>你可以使用以下命令停止任务：</p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">launchctl unload xxx</span><br></pre></td></tr></table></figure></p></li>
<li><p>查看任务状态：</p>
<p>你可以使用以下命令查看任务的状态：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">launchctl list | grep com.example.myjob</span><br></pre></td></tr></table></figure>
<p>请替换 <code>com.example.myjob</code> 为你的任务的 Label 值。</p>
<p>你还可以使用以下命令查看任务的日志：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tail -f /tmp/test.out</span><br></pre></td></tr></table></figure>
<p>请替换 <code>/tmp/test.out</code> 为你的任务的
<code>StandardOutPath</code> 值。</p></li>
<li><p>更多的定时任务设置：</p>
<p><code>launchd</code>
提供了多种方式来设置更精细的定时任务，可以根据分钟、小时等更加精确的时间间隔来执行任务。以下是一些示例：</p>
<ul>
<li><strong>按分钟执行任务</strong>：</li>
</ul>
<p>如果你希望定时任务每隔一定的分钟数执行一次，你可以使用
<code>StartInterval</code> 键来设置间隔。下面是一个示例：</p>
<p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>StartInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">integer</span>&gt;</span>600<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这将使任务每隔 10 分钟执行一次。</p>
<ul>
<li><strong>按小时执行任务</strong>：</li>
</ul>
<p>如果你希望任务按小时执行，你可以结合使用
<code>StartCalendarInterval</code> 和
<code>StartInterval</code>。例如，要在每小时的第 30 分钟执行任务：</p>
<p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>StartCalendarInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dict</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Minute<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>30<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dict</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>StartInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">integer</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这将使任务每隔一小时执行一次，并在每小时的第 30 分执行。</p>
<ul>
<li><strong>按天执行任务</strong>：</li>
</ul>
<p>如果你需要在特定时间执行任务，可以使用
<code>StartCalendarInterval</code>，如下所示：</p>
<p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>StartCalendarInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dict</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Hour<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>8<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Minute<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>0<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dict</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这将使任务在每天早上 8 点执行。</p>
<ul>
<li><strong>按周执行任务</strong>：</li>
</ul>
<p>你可以使用 <code>StartCalendarInterval</code>
来指定具体的星期几执行任务，例如，每周一早上 8 点：</p>
<p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>StartCalendarInterval<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dict</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Hour<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>8<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Minute<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>0<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">key</span>&gt;</span>Weekday<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">integer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dict</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这将使任务每周一早上 8 点执行。</p>
<p>通过合理设置 <code>StartInterval</code> 和
<code>StartCalendarInterval</code>，你可以创建几乎任何你想要的定时任务规则，以满足不同的需求。请根据你的具体需求修改上述示例来创建自定义的定时任务。</p></li>
</ol>
<p>你的任务现在应该会按计划执行。你可以根据需要编辑 plist
文件来更改触发时间或其他任务设置。</p>
]]></content>
  </entry>
  <entry>
    <title>Nvidia CUDA Architecture</title>
    <url>/2021/12/24/Nvidia-CUDA-Architecture/</url>
    <content><![CDATA[<h2 id="fermi-architecture">Fermi Architecture</h2>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/lCSuMscTkdenIt1.png" alt="img" style="zoom:50%;" /></th>
<th><img src="https://s2.loli.net/2022/05/23/muGjTriYMNvIFPe.png" alt="image-20211224153019867" style="zoom:45%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<span id="more"></span>
<ul>
<li>Host Interface： GPU，CPU，Memory通信的接口</li>
<li>Giga Thread Engine：任务管理器，管理所有正在进行的工作</li>
<li>Fermi架构拥有16个SM，SM属于硬件实体。每一个SM拥有21个CUDA
core，每一个CUDA
core拥有一个INT和一个FP计算单元；一个SM有16个LOAD/STORE单元，可以提供16线程同时读取/存储数据的能力；4个SFU单元，SFU：Special
Function Unit，特殊函数计算单元，包括sin，cos函数。</li>
</ul>
<h2 id="kepler-architecture">Kepler Architecture</h2>
<p>Kepler架构将SM重命名为SMX，其中大致结构并未改变，最明显的是增加了CUDA
Core的数量。一个SMX中有192个CUDA Core。</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/GtSyW7B8RVEPcN4.png" alt="img" style="zoom:50%;" /></th>
<th><img src="https://s2.loli.net/2022/05/23/vMbaX2oyzldWhEk.png" alt="img" style="zoom: 50%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h2 id="maxwell-architecture">Maxwell Architecture</h2>
<p>SMM变得更多了，架构变化不大。</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/U8NDAZhOJ9fQTRq.png" alt="img" style="zoom:75%;" /></th>
<th><img src="https://s2.loli.net/2022/05/23/PH2Xez4AhUSacwG.png" alt="image-20211224161723378" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h2 id="pascal-architecture">Pascal Architecture</h2>
<p>第一个加入Deep Learning相关硬件设置的架构，即：DP Unit。</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/8akQquFoem1RWPs.png"
alt="img" /></th>
<th><img src="https://s2.loli.net/2022/05/23/w163XcyputQokvg.jpg" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h2 id="volta-architecture">Volta Architecture</h2>
<p>第一个以Deep Learning为主的GPU架构。原本的CUDA
Core变成FP64，INT，FP32，TENSOR Core。</p>
<p><img src="https://s2.loli.net/2022/05/23/WTDqRt1fboANn4S.png" alt="image-20211224165854516" style="zoom:50%;" /></p>
<h2 id="turing-architecture">Turing Architecture</h2>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/MZvAIWFncLpNsyj.png" style="zoom:50%;" /></th>
<th><img src="https://s2.loli.net/2022/05/23/x8V5nFwOqokc46p.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h2 id="empere-architecture">Empere Architecture</h2>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th><img src="https://s2.loli.net/2022/05/23/8akQquFoem1RWPs.png" style="zoom:50%;" /></th>
<th><img src="https://s2.loli.net/2022/05/23/LPzeIAdm2DMgbpc.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
]]></content>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>Guided Filter</title>
    <url>/2021/10/13/Guided-Filter/</url>
    <content><![CDATA[<p>输入图p，导向图I， 输出图q，<span class="math inline">\(\Rightarrow
q_i = \sum_jW_{ij}(I)p_j\)</span>，其中i，j为pixel index，<span
class="math inline">\(W_{ij}\)</span>是导向图I的一个函数，与输入图p独立。</p>
<p>假设输出图q在一个窗口<span
class="math inline">\(w_i\)</span>中是导向图I的相信变换，即：<span
class="math inline">\(q_i = a_kI_i + b_k, \forall i \in w_k\)</span></p>
<span id="more"></span>
<p>这种模型保证了仅有在导向图I有边缘的时候，输出图也有边缘，<span
class="math inline">\(\nabla q = a\nabla I\)</span>，原理可以按照<a
href="https://sci-hubtw.hkvisa.net/10.1109/acv.2002.1182150">https://sci-hubtw.hkvisa.net/10.1109/acv.2002.1182150</a></p>
<p>为了确定<span
class="math inline">\(a_k,b_k\)</span>系数，有如下的优化函数。</p>
<p><span class="math inline">\(E(a_k, b_k) = \sum_{i \in
\omega_k}((a_kI_i + b_k - p_i)^2 + \epsilon a_k^2)\)</span></p>
<p>最终得到<span class="math inline">\(a_k,b_k\)</span>如下：</p>
<p><span class="math inline">\(a_k =
\frac{\frac{1}{\lvert\epsilon\rvert}\sum{i\in\omega_k(I_ip_i -
\mu_k\overline{p}_k)}}{\sigma_k^2 + \omega}\)</span></p>
<p><span class="math inline">\(b_k = \overline{p_k} -
a_k\mu_k\)</span></p>
<p>以偏导的方式求解<span class="math inline">\(a_k，b_k\)</span></p>
<p>对于输出图q，可以认为是输入图p减去其噪声，<span
class="math inline">\(q_i = p_i - n_i\)</span>，<span
class="math inline">\(n_i\)</span>表示噪声</p>
<p>对于输出图q与导向图I，有如下公式：<span class="math inline">\(\nabla
q_i = a \nabla I_i\)</span>， <span class="math inline">\(q_i = aI_i +
b\)</span></p>
<p>最小化输出图q与输入图p的差异，求解系数：</p>
<p><span class="math inline">\(\frac{\partial E}{\partial a_k} =
2\sum_{i}^{N}((a_kI_i + b_k - p_i)I_i + \epsilon a_k)\)</span></p>
<p><span class="math inline">\(\frac{\partial E}{\partial b_k} =
-2\sum_{i}^{N}(p_i - a_kI_i - b_k)\)</span></p>
<p>求解<span class="math inline">\(b_k\)</span></p>
<p><span class="math display">\[\begin{aligned}
&amp;\ \frac{\partial E}{\partial b_k} = -2\sum_{i}^{N}(p_i - a_kI_i -
b_k) = 0 \\
&amp;\ \Rightarrow Nb_k = \sum_{i}^n(p_i - a_kI_i) \\
&amp;\ \Rightarrow b_k =  \frac{1}{N} \sum_{i}^n(p_i - a_kI_i) \\
&amp;\ \Rightarrow b_k =  \frac{1}{N} \sum_{i}^np_i - a_k\frac{1}{N}
\sum_{i}^nI_i \\
&amp;\ \Rightarrow b_k =  p_k - a_k u_k \\
\end{aligned}\]</span></p>
<p><span class="math inline">\(p_k\)</span>和<span
class="math inline">\(u_k\)</span>是窗口<span
class="math inline">\(w_i\)</span>内，输入图<span
class="math inline">\(p_i\)</span>和导向图<span
class="math inline">\(I_i\)</span>的均值。</p>
<p>求解<span class="math inline">\(a_k\)</span></p>
<p><span class="math display">\[\begin{aligned}
&amp;\ \frac{\partial E}{\partial a_k} = 2\sum_{i}^{N}((a_kI_i + b_k -
p_i)I_i + \epsilon a_k) = 0 \\
&amp;\ \Rightarrow -\sum_{i}^Np_iI_i + \sum_{i}^Nb_kI_i +
\sum_{i}^Na_kI_i^2 + \sum_{i}^N \epsilon a_k = 0 \\
&amp;\ \Rightarrow \sum_{i}^Np_iI_i - \sum_{i}^Nb_kI_i =
\sum_{i}^Na_kI_i^2 + \sum_{i}^2\epsilon a_k \\
&amp;\ \Rightarrow \sum_{i}^Np_iI_i - \sum_{i}^N(p_k-a_ku_k)I_i =
a_k\sum_{i}^N(I_i^2 + \epsilon) \\
&amp;\ \Rightarrow \sum_{i}^Np_iI_i - \sum_{i}^Np_kI_i +
\sum_{i}^Na_ku_kI_i = a_k\sum_{i}^N(I_i^2 + \epsilon) \\
&amp;\ \Rightarrow \sum_{i}^Np_iI_i - p_k\sum_{i}^NI_i =
a_k\sum_{i}^N(I_i^2 + \epsilon - u_kI_i) \\
&amp;\ \Rightarrow a_k = \frac{\sum_{i}^Np_iI_i -
p_k\sum_{i}^NI_i}{\sum_{i}^N(I_i^2 + \epsilon - u_kI_i)} \\
&amp;\ \Rightarrow a_k = \frac{\sum_{i}^Np_iI_i -
\frac{1}{N}\sum_{i}^Np_i\sum_{i}^NI_i}{\sum_{i}^NI_i^2 -
\frac{1}{N}\sum_{i}^NI_i\sum_{i}^NI_i + \epsilon} \\
&amp;\ \Rightarrow a_k = \frac{\frac{1}{N}\sum_{i}^Np_iI_i -
\frac{1}{N}\sum_{i}^Np_i\frac{1}{N}\sum_{i}^NI_i}{\frac{1}{N}\sum_{i}^NI_i^2
- \frac{1}{N}\sum_{i}^NI_i\frac{1}{N}\sum_{i}^NI_i + \epsilon} \\
\end{aligned}\]</span></p>
<p>根据协方差公式</p>
<p><span class="math inline">\(var(X) = \frac{\sum_{i}^{N}(X_i-\overline
X)(X_i - \overline X)}{n-1}\)</span></p>
<p><span class="math inline">\(cov(X, Y) = E[(X - E[X])(Y -
E[Y])]\)</span></p>
<p><span class="math inline">\(cov(X, Y) = E[XY] - E[X][Y]\)</span></p>
<p><span class="math inline">\(a_k = \frac{cov(p_i, I_i)}{\sigma_k^2 +
\epsilon}\)</span></p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="attr">cv</span>::<span class="title class_">Mat</span> <span class="title function_">guidedFilter</span>(<span class="params">cv::Mat I, cv::Mat p, int r, double eps</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  % GUIDEDFILTER   O(1) time implementation of guided filter.</span></span><br><span class="line"><span class="comment">  %</span></span><br><span class="line"><span class="comment">  % - guidance image: I (should be a gray-scale/single channel image)</span></span><br><span class="line"><span class="comment">  % - filtering input image: p (should be a gray-scale/single channel image)</span></span><br><span class="line"><span class="comment">  % - local window radius: r</span></span><br><span class="line"><span class="comment">  % - regularization parameter: eps</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> _I;</span><br><span class="line">  I.<span class="title function_">convertTo</span>(_I, <span class="variable constant_">CV_64FC1</span>);</span><br><span class="line">  I = _I;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> _p;</span><br><span class="line">  p.<span class="title function_">convertTo</span>(_p, <span class="variable constant_">CV_64FC1</span>);</span><br><span class="line">  p = _p;</span><br><span class="line">  <span class="comment">//[hei, wid] = size(I);</span></span><br><span class="line">  int hei = I.<span class="property">rows</span>;</span><br><span class="line">  int wid = I.<span class="property">cols</span>;</span><br><span class="line">  <span class="comment">//N = boxfilter(ones(hei, wid), r); % the size of each local patch; N=(2r+1)^2 except for boundary pixels.</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> N;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(<span class="attr">cv</span>::<span class="title class_">Mat</span>::<span class="title function_">ones</span>(hei, wid,I.<span class="title function_">type</span>()), N, <span class="variable constant_">CV_64FC1</span>, <span class="attr">cv</span>::<span class="title class_">Size</span>(r, r));</span><br><span class="line">  <span class="comment">//mean_I = boxfilter(I, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_I;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(I, mean_I, <span class="variable constant_">CV_64FC1</span>, <span class="attr">cv</span>::<span class="title class_">Size</span>(r,r));</span><br><span class="line">  <span class="comment">//mean_p = boxfilter(p, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_p;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(p, mean_p, <span class="variable constant_">CV_64FC1</span>, <span class="attr">cv</span>::<span class="title class_">Size</span>(r,r));</span><br><span class="line">  <span class="comment">//mean_Ip = boxfilter(I.*p, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_Ip;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(I.<span class="title function_">mul</span>(p), mean_Ip, <span class="variable constant_">CV_64FC1</span>,</span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Size</span>(r, r));</span><br><span class="line">  <span class="comment">//cov_Ip = mean_Ip - mean_I .* mean_p; % this is the covariance of (I, p) in each local patch.</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> cov_Ip = mean_Ip - mean_I.<span class="title function_">mul</span>(mean_p);</span><br><span class="line">  <span class="comment">//mean_II = boxfilter(I.*I, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_II;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(I.<span class="title function_">mul</span>(I), mean_II, <span class="variable constant_">CV_64FC1</span>,</span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Size</span>(r, r));</span><br><span class="line">  <span class="comment">//var_I = mean_II - mean_I .* mean_I;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> var_I = mean_II - mean_I.<span class="title function_">mul</span>(mean_I);</span><br><span class="line">  <span class="comment">//a = cov_Ip ./ (var_I + eps); % Eqn. (5) in the paper;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> a = cov_Ip / (var_I + eps);</span><br><span class="line">  <span class="comment">//b = mean_p - a .* mean_I; % Eqn. (6) in the paper;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> b = mean_p - a.<span class="title function_">mul</span>(mean_I);</span><br><span class="line">  <span class="comment">//mean_a = boxfilter(a, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_a;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(a, mean_a, <span class="variable constant_">CV_64FC1</span>, <span class="attr">cv</span>::<span class="title class_">Size</span>(r,r));</span><br><span class="line">  mean_a = mean_a / N;</span><br><span class="line">  <span class="comment">//mean_b = boxfilter(b, r) ./ N;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> mean_b;</span><br><span class="line">  <span class="attr">cv</span>::<span class="title function_">boxFilter</span>(b, mean_b, <span class="variable constant_">CV_64FC1</span>, <span class="attr">cv</span>::<span class="title class_">Size</span>(r,r));</span><br><span class="line">  mean_b = mean_b / N;</span><br><span class="line">  <span class="comment">//q = mean_a .* I + mean_b; % Eqn. (8) in the paper;</span></span><br><span class="line">  <span class="attr">cv</span>::<span class="title class_">Mat</span> q = mean_a.<span class="title function_">mul</span>(I) + mean_b;</span><br><span class="line">  <span class="keyword">return</span> q;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Tips</title>
    <url>/2022/03/05/C-Tips/</url>
    <content><![CDATA[<ol type="1">
<li>自定义class，存在析构函数，那么需要同时定义或者删除拷贝构造函数和拷贝赋值函数。原因是，在拷贝构造或者拷贝复制的过程中，为浅拷贝，当程序结束，析构函数介入时，可能存在析构两次的情况。</li>
</ol>
<span id="more"></span>
<ol start="2" type="1">
<li><p>右值，int &amp;&amp;可以自动转换为int const &amp;。</p></li>
<li><p>__restrict关键字，告诉编译器，指针不存在重叠的情况，编译器可以进行优化，所有的非const指针都可以加上__restrict关键字，如：int
* __restrict a。对于vector容器，__restrict关键字不生效，可以尝试#pragma
omp simd或者#pragma GCC ivdep</p></li>
<li><p>关于malloc和new</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> *a = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">102400</span>];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> *a = (<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="number">102400</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br></pre></td></tr></table></figure></p>
<p>以上申请内存的两种语句，在实际生产环境，执行时并不会真正的分配内存，而是将这一段内存标记为不可用，即：invalid。待需要用到a数组：赋值或者其他操作时，会触发缺页中断，page
fault。此时进入内核，查询此段内存是否之前malloc过，如果查询到，那么内存标记为可用，此时程序正常运行，如果未查询到malloc记录，那么触发段错误，segmentation
fault。</p>
<p>以上两种申请内存的语句，不会进行置零操作，初始化数组时，内存被写入，此时操作系统才进行实际的内存分配，因此测试两次内存赋值操作会发现时间不同。对于new操作符有一个简便方法</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> *a = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">102400</span>]&#123;&#125;;</span><br></pre></td></tr></table></figure></p>
<p>常见的自定义String类中，无参数构造函数也可以进行以下简单的定义：注意new
char[1]后面的一对大括号</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">String::<span class="built_in">String</span>() : m_length&#123;<span class="number">0</span>&#125;, m_string&#123;<span class="keyword">new</span> <span class="type">char</span>[<span class="number">1</span>]&#123;&#125;&#125;&#123;&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>原子操作</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">type __sync_fetch_and_add (type *ptr, type value, ...) <span class="comment">// 将value加到*ptr上，结果更新到*ptr，并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_fetch_and_sub (type *ptr, type value, ...) <span class="comment">// 从*ptr减去value，结果更新到*ptr，并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_fetch_and_or (type *ptr, type value, ...) <span class="comment">// 将*ptr与value相或，结果更新到*ptr， 并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_fetch_and_and (type *ptr, type value, ...) <span class="comment">// 将*ptr与value相与，结果更新到*ptr，并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_fetch_and_xor (type *ptr, type value, ...) <span class="comment">// 将*ptr与value异或，结果更新到*ptr，并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_fetch_and_nand (type *ptr, type value, ...) <span class="comment">// 将*ptr取反后，与value相与，结果更新到*ptr，并返回操作之前*ptr的值</span></span><br><span class="line">type __sync_add_and_fetch (type *ptr, type value, ...) <span class="comment">// 将value加到*ptr上，结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line">type __sync_sub_and_fetch (type *ptr, type value, ...) <span class="comment">// 从*ptr减去value，结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line">type __sync_or_and_fetch (type *ptr, type value, ...) <span class="comment">// 将*ptr与value相或， 结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line">type __sync_and_and_fetch (type *ptr, type value, ...) <span class="comment">// 将*ptr与value相与，结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line">type __sync_xor_and_fetch (type *ptr, type value, ...) <span class="comment">// 将*ptr与value异或，结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line">type __sync_nand_and_fetch (type *ptr, type value, ...) <span class="comment">// 将*ptr取反后，与value相与，结果更新到*ptr，并返回操作之后新*ptr的值</span></span><br><span class="line"><span class="type">bool</span> __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...) <span class="comment">// 比较*ptr与oldval的值，如果两者相等，则将newval更新到*ptr并返回true</span></span><br><span class="line">type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...) <span class="comment">// 比较*ptr与oldval的值，如果两者相等，则将newval更新到*ptr并返回操作之前*ptr的值</span></span><br><span class="line">__sync_synchronize (...) <span class="comment">// 发出完整内存栅栏，内存屏障</span></span><br><span class="line">type __sync_lock_test_and_set (type *ptr, type value, ...) <span class="comment">// 将value写入*ptr，对*ptr加锁，并返回操作之前*ptr的值</span></span><br><span class="line"><span class="type">void</span> __sync_lock_release (type *ptr, ...) <span class="comment">// 将0写入到*ptr，（类似对*ptr解锁）</span></span><br></pre></td></tr></table></figure></p>
<p>c++11中atomic</p>
<ol type="1">
<li>atomic_flag</li>
</ol>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::atomic_flag LOCK = ATOMIC_FLAG_INIT; <span class="comment">// 原子布尔类型</span></span><br><span class="line">LOCK.<span class="built_in">test_and_set</span>(); <span class="comment">//被设置，则返回true; 否则，返回false</span></span><br><span class="line">LOCK.<span class="built_in">clear</span>(); <span class="comment">// 清除atomic_flag对象</span></span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>atomic对int, char, bool等数据结构进行原子性封装</li>
</ol>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::atomic&lt;<span class="type">int</span>&gt; <span class="title">counter</span><span class="params">(<span class="number">2</span>)</span></span>; <span class="comment">// 等同于counter.load(2);</span></span><br><span class="line"><span class="type">int</span> old = counter.<span class="built_in">fetch_add</span>(<span class="number">2</span>); <span class="comment">// 等同于counter+=2; 注意：counter = counter + 1;并不是原子操作; fetch_add会返回旧值</span></span><br><span class="line">counter.<span class="built_in">load</span>(); <span class="comment">// 读取，等同于std::cout &lt;&lt; counter &lt;&lt; std::endl;</span></span><br><span class="line"><span class="type">int</span> old = counter.<span class="built_in">exchange</span>(<span class="number">3</span>); <span class="comment">// 交换并返回旧值，old = 2</span></span><br><span class="line"><span class="type">bool</span> equal = counter.<span class="built_in">compare_exchange_strong</span>(old, <span class="keyword">new</span>); <span class="comment">// equal with old, counter = new, 返回true, 此处的old为引用，不能直接传入右值2</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Sensor Noise Model Calibration</title>
    <url>/2021/09/26/Sensor-Noise-Model-Calibration/</url>
    <content><![CDATA[<figure>
<img src="https://s2.loli.net/2022/05/23/sroq9vQ7fJOWNC8.png"
alt="image-20210927104516396" />
<figcaption aria-hidden="true">image-20210927104516396</figcaption>
</figure>
<p>图片来源：<a
href="http://graphics.cs.cmu.edu/courses/15-463/2020_fall/lectures/lecture2.pdf">CMU
Computational Photography, Fall 2020</a></p>
<span id="more"></span>
<p>Pipeline中绿色框部分会引入噪声，具体如下:</p>
<figure>
<img src="https://s2.loli.net/2022/05/23/l3LasJfYkmROzWy.png"
alt="image-20210927105235305" />
<figcaption aria-hidden="true">image-20210927105235305</figcaption>
</figure>
<p>图片来源：<a
href="http://graphics.cs.cmu.edu/courses/15-463/2020_fall/lectures/lecture2.pdf">CMU
Computational Photography, Fall 2020</a></p>
<p>具体而言会有以下三种noise：</p>
<ol type="1">
<li><p>Photon noise，也称Shot noise
光粒子到达的随机性，符合泊松分布</p></li>
<li><p>Dark noise</p>
<p>暗电流的影响，即便没有光粒子到达，也会因为元器件本身的特性产生噪声，一般而言温度越高，噪声越大，符合均值0的高斯分布</p></li>
<li><p>Read noise</p>
<p>信号放大过程中、模数转换过程中引入的噪声，俗称：gain、ADC；符合均值0的高斯分布</p></li>
</ol>
<p>因此可以在Raw denoise的相关论文中找到以下noise model。</p>
<blockquote>
<p><a
href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Mildenhall_Burst_Denoising_With_CVPR_2018_paper.pdf">Google:
Burst Denoising with Kernel Prediction Networks</a></p>
</blockquote>
<p><span class="math display">\[
x_p \sim N(y_p, \sigma_r^2 + \sigma_s y_p)
\]</span></p>
<blockquote>
<p><a href="https://arxiv.org/abs/1811.11127">Google: Unprocessing
Images for Learned Raw Denoising</a></p>
</blockquote>
<p><span class="math display">\[
y \sim N(\mu=x, \sigma^2=\lambda_{read} + \lambda_{shot} x) \to
N(\mu=x,\sigma^2=g_d^2\sigma_r^2 + g_dg_ax)
\]</span></p>
<p>其中digital gain <span class="math inline">\(g_d\)</span>， analog
gain <span class="math inline">\(g_a\)</span>，read noise的固定方差<span
class="math inline">\(\sigma^2\)</span> <span class="math display">\[
\lambda_{read}=g_d^2 \sigma_r^2, \ \lambda_{shot} = g_d g_a
\]</span></p>
<p>以下对上面的噪声联合分布进行推导。</p>
<p>(Photon)Shot noise与环境照度，曝光有关。令环境照度$ $ ，光电转换效率$
$，曝光时间t, 暗电流强度D</p>
<p>Shot noise满足泊松分布 <span class="math display">\[
n \sim Possion(\varphi, \alpha, t) = Possion(\varphi \cdot \alpha \cdot
t)
\]</span> Dark
noise与曝光有关，曝光时间越长，元器件温度越高，暗电流影响越大，与环境光无关，满足泊松分布
<span class="math display">\[
n \sim Possion(D \cdot t)
\]</span> 那么电信号L满足泊松分布，Shot noise和Dark noise的联合分布
<span class="math display">\[
L \sim Possion(t \cdot (\alpha \cdot \varphi + D))
\]</span> 信号放大过程中产生Read noise，模数转换过程中产生ADC
noise，两种noise满足均值为0的高斯分布</p>
<p><span class="math display">\[
n_{read} \sim Normal(0, \sigma_{read})
\]</span></p>
<p><span class="math display">\[
n_{ADC} \sim Normal(0, \sigma_{ADC})
\]</span></p>
<p>电信号L放大后表示为G，放大的增益g，g与ISO有关 <span
class="math inline">\(g = k \cdot ISO\)</span>，<span
class="math inline">\(G = L \cdot g + n_{read} \cdot g\)</span>，</p>
<p>经过ADC后信号：<span class="math inline">\(I = G +
n_{ADC}\)</span></p>
<p>最终信号I表示为： <span class="math display">\[
I = L \cdot g + n_{read} \cdot g + n_{ADC}
\]</span> 计算信号的均值和方差 <span class="math display">\[
E(I) = g \cdot E(L) + g \cdot E(n_{read}) + E(n_{ADC})
\]</span> 由于read noise和ADC noise均符合均值为0的高斯分布，因此 <span
class="math display">\[
E(I) = g \cdot E(L) = g \cdot t \cdot (\alpha \cdot \varphi + D)
\]</span> 方差 <span class="math display">\[
\begin{aligned}
\sigma(I)^2 &amp;= \sigma(L \cdot g)^2 + \sigma(n_{read} \cdot g)^2 +
\sigma(n_{ADC})^2 \\
&amp;= g^2 \cdot t \cdot (\alpha \cdot \varphi + D) + g^2 \cdot
\sigma(n_{read})^2 + \sigma(n_{ADC})^2
\end{aligned}
\]</span> read noise和ADC noise都属于加性噪声，可以合并 <span
class="math display">\[
I = L \cdot g + n_{read} + n_{ADC} = L \cdot g + n_{Add}
\]</span></p>
<p><span class="math display">\[
n_{Add} = n_{read} \cdot g + n_{ADC}
\]</span></p>
<p>方差可以表示为： <span class="math display">\[
\sigma(I)^2 = g^2 \cdot t \cdot (\alpha \cdot \varphi + D) +
\sigma(n_{Add})^2
\]</span> 一直暗电流，即：black level，那么可以消除暗电流D <span
class="math display">\[
E(I) = g \cdot t \cdot (\alpha \cdot \varphi + D) = g \cdot t \cdot
(\alpha \cdot 0 + D) = g \cdot t \cdot D
\]</span> 估计出暗电流的影响，可以将其从信号中减去，得到以下表达： <span
class="math display">\[
E(I) = g \cdot t \cdot \alpha \cdot \varphi
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\sigma(I)^2 &amp;= g^2 \cdot t \cdot \alpha \cdot \varphi +
\sigma(n_{Add})^2 \\
&amp;= g \cdot E(I) + \sigma(n_{Add})^2
\end{aligned}
\]</span></p>
<p>因此可以看出联合分布的方差是一个线性关系，可与通过最小二乘法进行拟合。</p>
<p>在实际的噪声估计中当做是 <span class="math inline">\(pixel \ value
\to x\)</span>，最终得到开头的推导：<span class="math inline">\(g \to
\lambda_{shot}, \sigma(n_{add})^2 \to \lambda_{read} \to
g_d^2\sigma_r^2\)</span> <span class="math display">\[
y \sim N(\mu=x, \sigma^2=\lambda_{read} + \lambda_{shot} x)
\]</span></p>
<p>实际上，<span class="math inline">\(\lambda_{read}\)</span>和 <span
class="math inline">\(\lambda_{shot}\)</span>都是与ISO强相关的，在噪声标定1.0版本，需要对ISO
100，300，500，800，1600，3200进行标定，得到RGB三通道<span
class="math inline">\(\lambda_{read}\)</span>和<span
class="math inline">\(\lambda_{shot}\)</span>共3*2*6=36组参数，在其它ISO值时，需要对齐进行插值。可能会引入不必要的误差，因此在噪声标定2.0版本中，将ISO作为参数引入标定过程。针对Sony
sensor，有一个比较通用的公式：<span class="math inline">\(g_d \cdot g_a
= \frac{ISO}{100}\)</span>，此时我们<span
class="math inline">\(\lambda_{read}\)</span>和<span
class="math inline">\(\lambda_{shot}\)</span>进行二次拟合，拟合的目标如下：
<span class="math display">\[
\lambda_{shot} = S \cdot g_d \cdot g_a = S \cdot \frac{ISO}{100}
\]</span></p>
<p><span class="math display">\[
\lambda_{read} = R_0 \cdot (g_d \cdot g_a)^2 + R_1 = R_0 \cdot
\frac{ISO}{100} + R_1
\]</span></p>
<p>此时将ISO作为参数引入标定过程，未来在噪声估计时会更精准。</p>
<p>总结不同噪声在不同场景下的主导地位：</p>
<table>
<thead>
<tr>
<th style="text-align: left;">regime</th>
<th>dominant noise</th>
<th>notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">bright noise</td>
<td>photon noise</td>
<td>scene-dependent</td>
</tr>
<tr>
<td style="text-align: left;">dark noise</td>
<td>read and ADC noise</td>
<td>scene-independent</td>
</tr>
<tr>
<td style="text-align: left;">low iso</td>
<td>ADC noise</td>
<td>post-gain</td>
</tr>
<tr>
<td style="text-align: left;">high iso</td>
<td>photon and read noise</td>
<td>pre-gain</td>
</tr>
<tr>
<td style="text-align: left;">long exposure</td>
<td>dark noise</td>
<td>thermal dependence</td>
</tr>
</tbody>
</table>
]]></content>
      <tags>
        <tag>Sensor</tag>
        <tag>Noise</tag>
        <tag>Model</tag>
        <tag>Calibration</tag>
      </tags>
  </entry>
  <entry>
    <title>图像平坦区域检测(Flat Area Detection)</title>
    <url>/2023/10/24/%E5%9B%BE%E5%83%8F%E5%B9%B3%E5%9D%A6%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B-Flat-Area-Detection/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>使用opecv进行平坦区域检测</p>
<span id="more"></span>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;opencv2/opencv.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CLAMP(x, a, b) (MAX(a, MIN(x, b)))</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">flat_gradient_cpu</span><span class="params">(Mat &amp;src, Mat &amp;dst, <span class="type">const</span> <span class="type">float</span> flatGradientThresh, <span class="type">bool</span> ones = <span class="literal">false</span>)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> width  = src.cols;</span><br><span class="line">    <span class="type">int</span> height = src.rows;</span><br><span class="line">    <span class="type">int</span> one    = (ones) ? <span class="number">1</span> : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *data_src = (<span class="type">float</span> *) src.data;</span><br><span class="line">    <span class="type">float</span> *data_dst = (<span class="type">float</span> *) dst.data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; width; j++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> x   = j;</span><br><span class="line">            <span class="type">int</span> y   = i;</span><br><span class="line">            <span class="type">int</span> pos = y * width + x;</span><br><span class="line"></span><br><span class="line">            data_dst[pos] = <span class="number">1.0f</span>;</span><br><span class="line">            <span class="keyword">if</span> (<span class="number">0</span> == x || <span class="number">0</span> == y || (width - <span class="number">1</span>) == x || (height - <span class="number">1</span>) == y) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">float</span> lrGrad   = (<span class="built_in">fabs</span>(data_src[pos + <span class="number">1</span>] - data_src[pos - <span class="number">1</span>]));</span><br><span class="line">            <span class="type">float</span> tbGrad   = (<span class="built_in">fabs</span>(data_src[(y + <span class="number">1</span>) * width + x] - data_src[(y - <span class="number">1</span>) * width + x]));</span><br><span class="line">            <span class="type">float</span> trblGrad = (<span class="built_in">fabs</span>(data_src[(y - <span class="number">1</span>) * width + x + <span class="number">1</span>] - data_src[(y + <span class="number">1</span>) * width + x - <span class="number">1</span>]));</span><br><span class="line">            <span class="type">float</span> tlbrGrad = (<span class="built_in">fabs</span>(data_src[(y - <span class="number">1</span>) * width + x - <span class="number">1</span>] - data_src[(y + <span class="number">1</span>) * width + x + <span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">            <span class="type">float</span> minGradClip = (<span class="built_in">min</span>(tbGrad, <span class="built_in">min</span>(trblGrad, tlbrGrad)));</span><br><span class="line">            <span class="type">float</span> minGrad     = (<span class="built_in">min</span>(lrGrad, minGradClip));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (minGrad &gt; flatGradientThresh) &#123;</span><br><span class="line">                <span class="type">float</span> invGrad = <span class="number">1.0f</span> / (minGrad - flatGradientThresh);</span><br><span class="line">                data_dst[pos] = <span class="built_in">CLAMP</span>(invGrad, <span class="number">0.0f</span>, <span class="number">1.0f</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">flat_3dark_thresh</span><span class="params">(Mat &amp;src, Mat &amp;src2, Mat &amp;src3, Mat &amp;net, <span class="type">const</span> <span class="type">float</span> dark_thresh)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> width  = src.cols;</span><br><span class="line">    <span class="type">int</span> height = src.rows;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *data_src  = (<span class="type">float</span> *) src.data;</span><br><span class="line">    <span class="type">float</span> *data_src2 = (<span class="type">float</span> *) src<span class="number">2.</span>data;</span><br><span class="line">    <span class="type">float</span> *data_src3 = (<span class="type">float</span> *) src<span class="number">3.</span>data;</span><br><span class="line">    <span class="type">float</span> *data_Net  = (<span class="type">float</span> *) net.data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; width; j++) &#123;</span><br><span class="line">            <span class="type">int</span> pos = i * width + j;</span><br><span class="line"></span><br><span class="line">            <span class="type">float</span> elem1 = (<span class="number">1.0f</span> - data_src[pos]);</span><br><span class="line">            <span class="type">float</span> elem2 = (<span class="number">1.0f</span> - data_src2[pos]);</span><br><span class="line">            <span class="type">float</span> elem3 = (<span class="number">1.0f</span> - data_src3[pos]);</span><br><span class="line"></span><br><span class="line">            elem1 = (elem1 + elem2 + elem3);</span><br><span class="line">            elem1 = <span class="number">1.0f</span> - (<span class="built_in">CLAMP</span>(elem1, <span class="number">0.0f</span>, <span class="number">1.0f</span>));</span><br><span class="line"></span><br><span class="line">            data_src[pos] = (data_Net[pos] &lt; dark_thresh) ? <span class="number">1.0f</span> : elem1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">flat_denoise_mask</span><span class="params">(Mat &amp;netDst, Mat &amp;flat_mask)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> flat_grad_thresh = <span class="number">0.5</span>;</span><br><span class="line"></span><br><span class="line">    Mat netDownX2  = <span class="built_in">Mat</span>(netDst.<span class="built_in">size</span>() / <span class="number">2</span>, netDst.<span class="built_in">type</span>());</span><br><span class="line">    Mat maskDownX2 = <span class="built_in">Mat</span>(flat_mask.<span class="built_in">size</span>() / <span class="number">2</span>, flat_mask.<span class="built_in">type</span>());</span><br><span class="line">    Mat netDownX4  = <span class="built_in">Mat</span>(netDownX<span class="number">2.</span><span class="built_in">size</span>() / <span class="number">2</span>, netDownX<span class="number">2.</span><span class="built_in">type</span>());</span><br><span class="line">    Mat maskDownX4 = <span class="built_in">Mat</span>(maskDownX<span class="number">2.</span><span class="built_in">size</span>() / <span class="number">2</span>, maskDownX<span class="number">2.</span><span class="built_in">type</span>());</span><br><span class="line"></span><br><span class="line">    Mat flatMaskUpBy2 = <span class="built_in">Mat</span>(flat_mask.<span class="built_in">size</span>(), flat_mask.<span class="built_in">type</span>());</span><br><span class="line">    Mat flatMaskUpBy4 = <span class="built_in">Mat</span>(flat_mask.<span class="built_in">size</span>(), flat_mask.<span class="built_in">type</span>());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">flat_gradient_cpu</span>(netDst, flat_mask, flat_grad_thresh, <span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">resize</span>(netDst, netDownX2, netDownX<span class="number">2.</span><span class="built_in">size</span>(), <span class="number">0</span>, <span class="number">0</span>, INTER_NEAREST);</span><br><span class="line">    <span class="built_in">flat_gradient_cpu</span>(netDownX2, maskDownX2, flat_grad_thresh, <span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">resize</span>(netDownX2, netDownX4, netDownX<span class="number">4.</span><span class="built_in">size</span>(), <span class="number">0</span>, <span class="number">0</span>, INTER_NEAREST);</span><br><span class="line">    <span class="built_in">flat_gradient_cpu</span>(netDownX4, maskDownX4, flat_grad_thresh, <span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">resize</span>(maskDownX2, flatMaskUpBy2, flatMaskUpBy<span class="number">2.</span><span class="built_in">size</span>(), <span class="number">0</span>, <span class="number">0</span>, INTER_NEAREST);</span><br><span class="line">    <span class="built_in">resize</span>(maskDownX4, flatMaskUpBy4, flatMaskUpBy<span class="number">4.</span><span class="built_in">size</span>(), <span class="number">0</span>, <span class="number">0</span>, INTER_NEAREST);</span><br><span class="line">    <span class="built_in">flat_3dark_thresh</span>(flat_mask, flatMaskUpBy2, flatMaskUpBy4, netDst, flat_grad_thresh);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Mat img = <span class="built_in">imread</span>(<span class="string">&quot;/Users/huziliang/Documents/C++/funny/flat_area.png&quot;</span>, IMREAD_GRAYSCALE);</span><br><span class="line">    Mat img_f, dst_f;</span><br><span class="line">    img.<span class="built_in">convertTo</span>(img_f, CV_32FC1);</span><br><span class="line">    <span class="built_in">boxFilter</span>(img_f, img_f, <span class="number">-1</span>, <span class="built_in">Size</span>(<span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line">    dst_f = Mat::<span class="built_in">zeros</span>(img_f.<span class="built_in">size</span>(), img_f.<span class="built_in">type</span>());</span><br><span class="line">    <span class="built_in">flat_denoise_mask</span>(img_f, dst_f);</span><br><span class="line">    <span class="built_in">imwrite</span>(<span class="string">&quot;/Users/huziliang/Documents/C++/funny/flat_area_result.png&quot;</span>, dst_f * <span class="number">255.0f</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>OpenCV</tag>
        <tag>Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>DLSS发展历程</title>
    <url>/2025/10/12/dlss4-0%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="nvidia-dlss-历年发展技术分析">NVIDIA DLSS 历年发展技术分析</h1>
<p>近年来，随着实时图形渲染对画质和性能的双重追求，NVIDIA
推出的深度学习超采样技术（Deep Learning Super Sampling，简称
DLSS）成为业界热点。从最初的 DLSS 1.0 到最新一代 DLSS
4.0，技术持续演进，本文将梳理 DLSS
各代技术路线及其核心升级点，并结合实际应用分析其影响。</p>
<h2 id="一dlss-1.0深度学习抗锯齿的起点">一、DLSS
1.0：深度学习抗锯齿的起点</h2>
<p><strong>发布时间</strong>：2018年末（随RTX 20系列发布）</p>
<p><strong>主要特性与原理</strong>： -
采用端到端神经网络，用输入帧与低分辨率深度缓冲生成高分辨率输出图像。 -
强调“图像重建”与抗锯齿，依赖大量离线预训练数据。 -
必须针对每一款游戏单独训练，通用性与适配性不足。</p>
<p><strong>优缺点</strong>： - 在部分游戏和场景下效果优秀（如FFXV等）。
- 细节重建和运动画面表现不稳定，容易出现图像模糊、鬼影和假影等现象。</p>
<hr />
<h2 id="二dlss-2.0通用超分辨率方案">二、DLSS 2.0：通用超分辨率方案</h2>
<p><strong>发布时间</strong>：2020年3月</p>
<p><strong>主要升级点</strong>： - 采用基于“时域信息积累”的全新 AI
超采样架构。 -
输入信息更加丰富：当前帧低分辨率渲染、运动矢量、深度图，以及历史帧数据。
-
引入通用型神经网络，无需为每款游戏单独训练，大大提升适配速度和推广力度。
- 增加多种质量模式（质量、平衡、性能、超性能）。</p>
<p><strong>效果提升</strong>： -
显著提升清晰度和细节还原能力，运动过程中的残影、模糊大幅减少。 -
大部分场景下接近原生分辨率，甚至部分细节超越原生渲染。</p>
<p><strong>应用范围</strong>： - 成为主流 3A
大作首选超分辨率方案，如《赛博朋克2077》、《荒野大镖客2》等大量游戏支持。</p>
<hr />
<h2 id="三dlss-3.0ai-帧生成">三、DLSS 3.0：AI 帧生成</h2>
<p><strong>发布时间</strong>：2022年9月（随 RTX 40 系列 Ada
架构发布）</p>
<p><strong>核心创新</strong>： - 新增 Optical Multi Frame
Generation（光学多帧生成），利用 AI 生成“中间帧”。 -
不同于前两代仅提升分辨率，DLSS 3.0 可插入 AI
合成新帧，实现帧率倍增（Frame Generation）。 - 需要专用硬件（Ada
架构中的 Optical Flow Accelerator）。</p>
<p><strong>原理简述</strong>： -
综合历史帧、运动矢量和光流数据预测插值帧，大幅提升帧率尤其在 CPU
受限场景下效果明显。 - AI 插帧仅处理视觉上属于“镜头中移动对象”，UI
以及输入延迟等需结合 NVIDIA Reflex 技术共同优化。</p>
<p><strong>优势与挑战</strong>： -
提升流畅度和体验，但极端场景下可能出现帧间“插帧假影”、“输入延迟提升”等问题。</p>
<hr />
<h2 id="四dlss-3.5全路径光追优化">四、DLSS 3.5：全路径光追优化</h2>
<p><strong>发布时间</strong>：2023年</p>
<p><strong>关键进步</strong>： - 引入 Ray Reconstruction（AI
光追重建）模块，用 AI 网络替代传统的降噪器（Denoiser）。 -
目标是让低采样路径下的光线追踪画质更接近高采样水平，提升全路径光追场景（如Cyberpunk
2077：RT Overdrive模式）下清晰度、细节与光照表现。 -
软硬件适配性增强：DLSS 3.5 的 AI 光追重建可在RTX
20/30/40全系列显卡上运行。</p>
<hr />
<h2 id="五dlss-4.0ai-超分新时代">五、DLSS 4.0：AI 超分新时代</h2>
<p>根据 <a
href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA
官方 DLSS 技术页面</a>，目前已经披露的 DLSS 4.0 技术细节包括：</p>
<p><strong>核心特性：</strong> -
<strong>第四代深度学习超采样网络</strong>：DLSS 4.0 进一步升级了 AI
模型，提升在极低分辨率和复杂场景下的细节还原能力，使整体画面更加锐利、动态更自然。
- <strong>多帧与时空融合重建</strong>：结合多帧信息，AI
网络不仅利用当前帧像素，还利用历史帧数据、运动矢量与高级光流信息，实现更精确的时空超分辨率重建。
- <strong>新一代光流引擎</strong>（Optical Flow
Accelerator）：硬件协同优化，极大提升运动估算与插帧精度。 -
<strong>低延迟帧生成优化</strong>：在 DLSS 3.0 Frame Generation
基础上进一步降低端到端延迟，提升响应性，改善输入体验，适配 Reflex
全链路优化。 - <strong>全平台/端到端渲染链路支持</strong>：DLSS 4.0 覆盖
PC 游戏、云游戏和未来的 XR 应用场景，接口开放且可跨平台适配。</p>
<p><strong>技术实现要点：</strong> -
<strong>大规模神经网络升级</strong>：采用更多层次和参数的神经网络，显著提升在复杂光照、运动与极低分辨率场景下的超分还原能力。
-
<strong>实时动态权重调节</strong>：根据游戏场景与分辨率动态切换模型权重，兼顾画质与性能。
-
<strong>智能时域降噪</strong>：自适应处理高速运动、粒子特效、半透明等极易失真的区域，降低伪影与残影。</p>
<p><strong>兼容性：</strong> - 预计在下一代 RTX 显卡（如 Blackwell
架构）上率先支持，未来逐步向更多 GPU 平台扩展。部分功能也与 RTX 20/30/40
系列兼容（以官方公布为准）。</p>
<p>更多官方信息可参考：<a
href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA
GeForce DLSS 4 Details</a></p>
<p>如需详细英文技术白皮书或公开演讲资料，可持续关注 GTC
及相关开发者文档。</p>
<hr />
<h2 id="六总结与展望">六、总结与展望</h2>
<p>DLSS 已成为 NVIDIA RTX 平台的核心卖点和创新引擎，其从 1.0 到 4.0
的迭代，展现了 AI
技术对传统图形渲染方式的变革力量。未来，随着硬件算力提升和神经网络更深度集成，AI
超采样有望不仅刷新游戏体验，也重塑电影制作、虚拟现实、专业设计等各行各业的图形工作流。</p>
<blockquote>
<p><strong>相关链接</strong>：</p>
<ul>
<li><a
href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA
DLSS 官方介绍</a></li>
<li><a
href="https://www.eurogamer.net/digitalfoundry-2023-nvidia-dlss-in-depth">Digital
Foundry 针对 DLSS 的系列评测&amp;分析（英文）</a></li>
<li><a href="https://www.cyberpunk.net/zh-cn/news">赛博朋克 2077
技术细节：路径追踪与 AI 超分辨率</a></li>
</ul>
</blockquote>
<p>有任何 DLSS 技术与应用问题，欢迎留言交流！</p>
]]></content>
      <tags>
        <tag>超分辨率</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>ISP尝试解决高Gain下暗部发紫问题</title>
    <url>/2022/09/23/ISP%E5%B0%9D%E8%AF%95%E8%A7%A3%E5%86%B3%E9%AB%98Gain%E4%B8%8B%E6%9A%97%E9%83%A8%E5%8F%91%E7%B4%AB%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="暗部发紫解决方案">暗部发紫解决方案</h1>
<p>在黑暗环境(iso 9000 ~ iso 25600下拍摄的图像出现紫色现象，sensor:
imx586, 平台: SM8150, 仿真器版本: Qualcomm Spectra 380</p>
<span id="more"></span>
<p><img src="https://s2.loli.net/2023/10/16/jQlLTVtrhDxMNXC.png" /></p>
<p>左侧为原始图像, 右边为提亮后的图像, 可以看到明显紫色现象.</p>
<p>当增益大幅拉高时(gain 90 ~ gain 256),
灰度接近0的像素的噪点也会随之提升. BLC和ABF模块无法正确处理这些像素,
并且在经过AWB, Gamma, Color等所有增强阶段后, 会产生偏差.</p>
<p>下面的模拟显示了暗区去噪之前BPS与暗区去噪之后BPS的效果。</p>
<p>Pipeline 1: BLS → AWB → Denoise → Purple Bias Created</p>
<style>
td, th {
   border: none !important;
}
table tr:hover {
    background-color: background-color:rgba(0, 0, 0, 0) !important;
}
tbody tr:nth-of-type(odd) {
    background-color: background-color:rgba(0, 0, 0, 0) !important;
    }
</style>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr>
<td><img src="https://s2.loli.net/2023/10/16/ON7EKP5zpqGWoLA.png"></td>
<td><img src="https://s2.loli.net/2023/10/16/SC74Yf2Xkn6eDiB.png"></td>
</tr>
<tr>
<td>1 - linearization后的图像, R, G, B
噪声相同(噪声标准差具有类似的高斯形状)</td>
<td>2 - BLS后的图像: 小于BL值的像素设置为0</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr>
<td><img src="https://s2.loli.net/2023/10/16/e6BytVLcvIJnUdN.png"></td>
<td><img src="https://s2.loli.net/2023/10/16/XGLRlqeC5IaWFNE.png"></td>
</tr>
<tr>
<td>3 - AWB后的图像，红色和蓝色通道高斯比绿色通道的高斯大</td>
<td>4 - Denoise后的图像，产生了紫色偏差</td>
</tr>
</tbody>
</table>
<p>Pipeline 2: Denoise → BLS → AWB → Purple Bias Not Created</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr>
<td><img src="https://s2.loli.net/2023/10/16/ON7EKP5zpqGWoLA.png"></td>
<td><img src="https://s2.loli.net/2023/10/16/vbz6SKUCLmYa8MN.png"></td>
</tr>
<tr>
<td>1 - linearization后的图像, R, G, B
噪声相同(噪声标准差具有类似的高斯形状)</td>
<td>2 - Denoise后的图像，高斯STD明显减小</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr>
<td><img src="https://s2.loli.net/2023/10/16/EPW5T7dCKxveMOI.png"></td>
<td><img src="https://s2.loli.net/2023/10/16/HZxQ7ek4NTKvmrF.png"></td>
</tr>
<tr>
<td>3 - BLS后的图像: 没有小于BL值的像素设置为 0</td>
<td>4 - AWB后的图像, 未产生紫色偏差</td>
</tr>
</tbody>
</table>
<p>改进pedestal去除之前的暗区去噪, 唯一可用的模块是ABF,
因此除了修改其他ABF参数外,
启用ABF中的暗部去饱和功能并增加ABF的noise_std_lut的第一个值.</p>
<p>紫色问题经过验证可以部分改善, 但是如果想要完全去除紫色像素时,
细节被严重破坏, 图像显得比以前更绿,
因此只能在细节和紫色噪声之间找到平衡.</p>
<p>目前高通平台上Raw Domain去噪模块(ABF)还不能很好地处理此类问题.
ABF可以通过更强的去噪来缓解紫色问题, 但同时细节也会丢失.
因此需要有更好的Raw Domain去噪算法, 一方面可以控制噪声,
另一方面可以尽可能保留细节.</p>
<p>还有第二套方案可供选择.</p>
<p>BLS模块: 目标手机拍摄几张黑图, 导入demux模块进行BLS calibrition,
得到一组BLS参数, 然后分别对RGGB四个通道分别增加一点BLS的值.</p>
<p>AWB模块: fine tune 3A中AWB的值</p>
<p>此方案的原因分析: 在极暗光环境下,
BLS的calibrition的值本就容易估算错误, 而后经过AWB放大之后,
紫色会更加明显.</p>
]]></content>
      <tags>
        <tag>ISP</tag>
      </tags>
  </entry>
  <entry>
    <title>多曝光融合网络Loss设计</title>
    <url>/2023/03/18/%E5%A4%9A%E6%9B%9D%E5%85%89%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9CLoss%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>对于包围式曝光融合网络, Loss设计如下:</p>
<p><span class="math display">\[
L(y, y^{*})=\left \| y - y^* \right \|_{1} +  \left \| \nabla y - \nabla
y^* \right \|_{1} + \gamma L_{gradsign}(y, y^*) + \eta L_{highsmooth}(y,
y^*)
\]</span></p>
<p>其中<span class="math inline">\(y\)</span>为融合得到的图像, <span
class="math inline">\(y^*\)</span>表示融合图像的标签, <span
class="math inline">\(\left \| y - y^* \right \|_{1}\)</span>表示L1范数,
即向量元素绝对值之和, <span
class="math inline">\(\nabla\)</span>表示求图像的梯度, <span
class="math inline">\(𝐿_{𝑔𝑟𝑎𝑑𝑠𝑖𝑔𝑛}\)</span>损失函数的作用是为了学习得到的图像的边缘过渡和真实图像贴合得更好,
消除由于包围式曝光不连续导致的图像拼接人工痕迹. <span
class="math inline">\(𝐿_{ℎ𝑖𝑔ℎ𝑠𝑚𝑜𝑜𝑡ℎ}\)</span>损失函数表示加大高亮区域的权重,
使得高亮区域效果更好, 缓解图像中高亮区域占整张图像比重太小的问题, <span
class="math inline">\(𝐻_{𝑡ℎ}\)</span>是高亮像素值的阈值; <span
class="math inline">\(\gamma\)</span>, <span
class="math inline">\(\eta\)</span>为常数, 表示损失函数权重,
可依效果需求要求进行调整.</p>
<p><span class="math display">\[
L_{gradsign}(y,y*)=ReLU(-\nabla y * \nabla y^{*})
\]</span></p>
<p><span class="math display">\[
L_{highsmooth}(y, y^*)=\left \| \nabla y - \nabla y^* \right \|_1 *
I(y^*, H_{th})
\]</span></p>
<p><span class="math display">\[
ReLU(x)= \begin{cases}x, x \geqslant 0 \\ 0, else \end {cases}
\]</span></p>
<p><span class="math display">\[
I(x,threshold)= \begin{cases}1, x \geqslant threshold \\ 0, else \end
{cases}
\]</span></p>
<p>另外还有两个Loss函数设计.</p>
<ol type="1">
<li><p>LumaGradLoss函数的操作是把prediction和groudtruth分别做一个global
average pooling操作downsample到8x8的图, 然后在计算L2 loss.
目的是保证prediction的整体亮度分布和groundtruth一致,
避免出现亮度反转的情况.</p></li>
<li><p>BlackRegLoss函数的操作是根据图像亮度值小于某个阈值threshold得到mask,
然后惩罚这些区域的1/4, 1/16等欠曝图像的融合权重.
目的是避免暗光区域受到欠曝图片的影响,
避免出现融合后图像天空等非过曝区域亮度值被拉暗的情况.</p></li>
</ol>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">def <span class="title class_">LumaGradLoss</span>(self, prediction, target, input):</span><br><span class="line">    prediction = torch.<span class="property">nn</span>.<span class="title class_">AdaptiveAvgPool2</span>d((<span class="number">8</span>,<span class="number">8</span>))(prediction)</span><br><span class="line">    target = torch.<span class="property">nn</span>.<span class="title class_">AdaptiveAvgPool2</span>d((<span class="number">8</span>,<span class="number">8</span>))(input[:,<span class="number">0</span>:<span class="number">4</span>,:,:])</span><br><span class="line"></span><br><span class="line">    target = torch.<span class="title function_">clamp</span>(target,<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">    prediction = torch.<span class="title function_">clamp</span>(prediction,<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    prediction_x_diff = prediction[:,:, :-<span class="number">1</span>, :-<span class="number">1</span>] - prediction[:, :, :-<span class="number">1</span>, <span class="number">1</span>:]</span><br><span class="line">    prediction_y_diff = prediction[:,:, :-<span class="number">1</span>, :-<span class="number">1</span>] - prediction[:, :, <span class="number">1</span>:, :-<span class="number">1</span>]</span><br><span class="line">    target_x_diff = target[:, :, :-<span class="number">1</span>, :-<span class="number">1</span>] - target[:,:,  :-<span class="number">1</span>, <span class="number">1</span>:]</span><br><span class="line">    target_y_diff = target[:, :, :-<span class="number">1</span>, :-<span class="number">1</span>] - target[:,:, <span class="number">1</span>:, :-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    error =  (target_x_diff-prediction_x_diff) ** <span class="number">2.0</span> + (target_y_diff-prediction_y_diff) ** <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">    loss = torch.<span class="title function_">mean</span>(error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">def <span class="title class_">BlackRegLoss</span>(self, logit, target,input_refs,  weight):</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">        black region regularization</span></span><br><span class="line"><span class="string">        penalty on 1/4, 1/16 in order to persuade network selecting more on 1/1 images</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    input_1 = input_refs[:, -<span class="number">12</span>:-<span class="number">8</span>, :, :]</span><br><span class="line">    raw_grey,_ = torch.<span class="title function_">max</span>(input_1, dim=<span class="number">1</span>, keepdim=<span class="title class_">True</span>)</span><br><span class="line"></span><br><span class="line">    low_mask = torch.<span class="title function_">where</span>(raw_grey &lt;= <span class="number">0.4</span>, torch.<span class="title function_">ones_like</span>(raw_grey).<span class="title function_">cuda</span>(), torch.<span class="title function_">zeros_like</span>(raw_grey).<span class="title function_">cuda</span>())</span><br><span class="line"></span><br><span class="line">    p2d = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">    tv_mask_h = nn.<span class="title class_">ReflectionPad2</span>d(p2d)(target)</span><br><span class="line">    tv_mask_h = tv_mask_h[:,:,<span class="number">1</span>:,:] - tv_mask_h[:,:,:-<span class="number">1</span>,:]</span><br><span class="line">    p2d = [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">    tv_mask_w = nn.<span class="title class_">ReflectionPad2</span>d(p2d)(target)</span><br><span class="line">    tv_mask_w = tv_mask_w[:,:,:,<span class="number">1</span>:] - tv_mask_w[:,:,:,:-<span class="number">1</span>]</span><br><span class="line">    tv_mask = torch.<span class="title function_">max</span>(torch.<span class="title function_">abs</span>(tv_mask_h), torch.<span class="title function_">abs</span>(tv_mask_w))</span><br><span class="line">    tv_mask,_ = torch.<span class="title function_">max</span>(tv_mask, dim = <span class="number">1</span>, keepdim = <span class="title class_">True</span>)</span><br><span class="line">    tv_mask = <span class="number">1.0</span> - tv_mask</span><br><span class="line"></span><br><span class="line">    low_mask = self.<span class="title function_">tf_high_light_dilate_blur</span>(low_mask * tv_mask, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> weight.<span class="property">shape</span>[<span class="number">1</span>] == <span class="number">3</span> or weight.<span class="property">shape</span>[<span class="number">1</span>] == <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="title function_">sum</span>(weight[:,<span class="number">1</span>:<span class="number">3</span>,:,:] * low_mask) / (torch.<span class="title function_">sum</span>(low_mask) * (<span class="number">2.0</span> ))  # only loss on <span class="number">1</span>/<span class="number">4</span>, <span class="number">1</span>/<span class="number">16</span> frames</span><br><span class="line">    elif weight.<span class="property">shape</span>[<span class="number">1</span>] == <span class="number">12</span>  or weight.<span class="property">shape</span>[<span class="number">1</span>] == <span class="number">13</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="title function_">sum</span>(weight[:,<span class="number">4</span>:<span class="number">4</span>*<span class="number">3</span>,:,:] * low_mask) / (torch.<span class="title function_">sum</span>(low_mask) * (<span class="number">2.0</span> * <span class="number">4</span>)) # only loss on <span class="number">1</span>/<span class="number">4</span>, <span class="number">1</span>/<span class="number">16</span> frames</span><br><span class="line">    <span class="attr">else</span>:</span><br><span class="line">        raise <span class="string">&#x27;Unsupport weight type&#x27;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>HDR</tag>
        <tag>Deep Learning</tag>
        <tag>Loss</tag>
      </tags>
  </entry>
  <entry>
    <title>不同架构下的CUDA Arch以及Gencode对应关系</title>
    <url>/2022/04/23/%E4%B8%8D%E5%90%8C%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84CUDA-Arch%E4%BB%A5%E5%8F%8AGencode%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<table style="width:100%;">
<colgroup>
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr>
<th>Fermi†</th>
<th>Kepler†</th>
<th>Maxwell‡</th>
<th>Pascal</th>
<th>Volta</th>
<th>Turing</th>
<th>Ampere</th>
<th>Hopper*</th>
<th>Lovelace</th>
</tr>
</thead>
<tbody>
<tr>
<td>sm_20</td>
<td>sm_30</td>
<td>sm_50</td>
<td>sm_60</td>
<td>sm_70</td>
<td>sm_75</td>
<td>sm_80</td>
<td>sm_90</td>
<td>sm_100?</td>
</tr>
<tr>
<td></td>
<td>sm_35</td>
<td>sm_52</td>
<td>sm_61</td>
<td>sm_72</td>
<td></td>
<td>sm_86</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>sm_37</td>
<td>sm_53</td>
<td>sm_62</td>
<td></td>
<td></td>
<td>sm_87</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<span id="more"></span>
<p><strong>†</strong> Fermi and Kepler are deprecated from CUDA 9 and 11
onwards</p>
<p><strong>‡</strong> Maxwell is deprecated from CUDA 11.6 onwards</p>
<ul>
<li>Hopper is NVIDIA’s “tesla-next” series, with a 5nm process,
replacing Ampere.</li>
</ul>
<h2 id="fermi-cards-cuda-3.2-until-cuda-8"><strong>Fermi cards (CUDA 3.2
until CUDA 8)</strong></h2>
<p>Deprecated from CUDA 9, support completely dropped from CUDA 10.</p>
<ul>
<li><strong>SM20 or SM_20, compute_30</strong> –GeForce 400, 500, 600,
GT-630.<strong><em>Completely dropped from CUDA 10
onwards.</em></strong></li>
</ul>
<h2 id="kepler-cards-cuda-5-until-cuda-10"><strong>Kepler cards (CUDA 5
until CUDA 10)</strong></h2>
<p>Deprecated from CUDA 11.</p>
<ul>
<li><strong>SM30 or <code>SM_30, compute_30</code> –</strong>Kepler
architecture (e.g. generic Kepler, GeForce 700, GT-730).Adds support for
unified memory programming<em><strong>Completely dropped from CUDA 11
onwards</strong>.</em></li>
<li><strong>SM35 or <code>SM_35, compute_35</code></strong> –Tesla
K40.Adds support for dynamic parallelism.<strong>Deprecated from CUDA
11, will be dropped in future versions</strong>.</li>
<li><strong>SM37 or <code>SM_37, compute_37</code></strong> –Tesla
K80.Adds a few more registers.<strong><em>Deprecated from CUDA 11, will
be dropped in future versions</em></strong>, strongly suggest replacing
with a <a
href="https://www.amazon.com/gp/product/B07JVNHFFX/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B07JVNHFFX&amp;linkCode=as2&amp;tag=arnonshimoni-20&amp;linkId=039f38074e50b581e71d500cd08bca85">32GB
PCIe Tesla V100</a>.</li>
</ul>
<h2 id="maxwell-cards-cuda-6-until-cuda-11"><strong>Maxwell cards (CUDA
6 until CUDA 11)</strong></h2>
<ul>
<li><strong>SM50
or <code>SM_50, compute_50</code></strong> –Tesla/Quadro M
series.<strong><em>Deprecated from CUDA 11, will be dropped in future
versions</em></strong>, strongly suggest replacing with a <a
href="https://www.amazon.com/gp/product/B07P6CDHS5/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B07P6CDHS5&amp;linkCode=as2&amp;tag=arnonshimoni-20&amp;linkId=fe1f6fa6ad408060f634a35bad4271ce">Quadro
RTX 4000</a> or <a
href="https://www.amazon.com/PNY-VCNRTXA6000-PB-NVIDIA-RTX-A6000/dp/B09BDH8VZV?crid=3QY8KCKXO3FB8&amp;keywords=rtx+a6000&amp;qid=1647969665&amp;sprefix=rtx+a6000%2Caps%2C174&amp;sr=8-1&amp;linkCode=ll1&amp;tag=arnonshimoni-20&amp;linkId=d292ba4d995d2b034a27441321668ffb&amp;language=en_US&amp;ref_=as_li_ss_tl">A6000</a>.</li>
<li><strong>SM52 or <code>SM_52, compute_52</code></strong> –Quadro
M6000 , GeForce 900, GTX-970, GTX-980, GTX Titan X.</li>
<li><strong>SM53 or <code>SM_53, compute_53</code></strong> –Tegra
(Jetson) TX1 / Tegra X1, Drive CX, Drive PX, Jetson Nano.</li>
</ul>
<h2 id="pascal-cuda-8-and-later"><strong>Pascal (CUDA 8 and
later)</strong></h2>
<ul>
<li><strong>SM60 or <code>SM_60, compute_60</code></strong> –Quadro
GP100, Tesla P100, DGX-1 (Generic Pascal)</li>
<li><strong>SM61 or <code>SM_61, compute_61</code></strong>–GTX 1080,
GTX 1070, GTX 1060, GTX 1050, GTX 1030 (GP108), GT 1010 (GP108) Titan
Xp, Tesla P40, Tesla P4, Discrete GPU on the NVIDIA Drive PX2</li>
<li><strong>SM62 or <code>SM_62, compute_62</code></strong> – Integrated
GPU on the NVIDIA Drive PX2, Tegra (Jetson) TX2</li>
</ul>
<h2 id="volta-cuda-9-and-later"><strong>Volta (CUDA 9 and
later)</strong></h2>
<ul>
<li><strong>SM70 or <code>SM_70, compute_70</code></strong> –DGX-1 with
Volta, Tesla V100, GTX 1180 (GV104), Titan V, Quadro GV100</li>
<li><strong>SM72 or <code>SM_72, compute_72</code></strong> –Jetson AGX
Xavier, Drive AGX Pegasus, Xavier NX</li>
</ul>
<h2 id="turing-cuda-10-and-later"><strong>Turing (CUDA 10 and
later)</strong></h2>
<ul>
<li><strong>SM75 or <code>SM_75, compute_75</code></strong> –GTX/RTX
Turing – GTX 1660 Ti, RTX 2060, <a
href="https://www.amazon.com/gp/product/B082P1BF7H/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B082P1BF7H&amp;linkCode=as2&amp;tag=arnonshimoni-20&amp;linkId=68e78b128dd90f652eb7796404e2126f">RTX
2070</a>, RTX 2080, Titan RTX, Quadro RTX 4000, Quadro RTX 5000, Quadro
RTX 6000, Quadro RTX 8000, Quadro T1000/T2000, Tesla T4</li>
</ul>
<h2 id="ampere-cuda-11.1-and-later"><strong>Ampere (CUDA 11.1 and
later)</strong></h2>
<ul>
<li><strong>SM80 or <code>SM_80, compute_80</code></strong> –NVIDIA A100
(the name “Tesla” has been dropped – GA100), NVIDIA DGX-A100</li>
<li><strong>SM86 or <code>SM_86, compute_86</code> –</strong> (from <a
href="https://docs.nvidia.com/cuda/ptx-compiler-api/index.html">CUDA
11.1 onwards</a>)Tesla GA10x cards, RTX Ampere – RTX 3080, GA102 – RTX
3090, RTX A2000, A3000, <a
href="https://www.amazon.com/PNY-NVIDIA-Quadro-A6000-Graphics/dp/B08NWGS4X1?msclkid=45987a9faa0411ec98c321cb30a0780e&amp;linkCode=ll1&amp;tag=arnonshimoni-20&amp;linkId=ccac0fed7c3cac61b4373d7dac6e7136&amp;language=en_US&amp;ref_=as_li_ss_tl">RTX
A4000</a>, A5000, <a
href="https://www.amazon.com/PNY-VCNRTXA6000-PB-NVIDIA-RTX-A6000/dp/B09BDH8VZV?crid=3QY8KCKXO3FB8&amp;keywords=rtx+a6000&amp;qid=1647969665&amp;sprefix=rtx+a6000%2Caps%2C174&amp;sr=8-1&amp;linkCode=ll1&amp;tag=arnonshimoni-20&amp;linkId=d292ba4d995d2b034a27441321668ffb&amp;language=en_US&amp;ref_=as_li_ss_tl">A6000</a>,
NVIDIA A40, GA106 – <a
href="https://www.amazon.com/gp/product/B08W8DGK3X/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=arnonshimoni-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B08W8DGK3X&amp;linkId=5cb5bc6a11eb10aab6a98ad3f6c00cb9">RTX
3060</a>, GA104 – RTX 3070, GA107 – RTX 3050, RTX A10, RTX A16, RTX A40,
A2 Tensor Core GPU</li>
<li><strong>SM87 or <code>SM_87, compute_8</code>7 –</strong> (from <a
href="https://docs.nvidia.com/cuda/ptx-compiler-api/index.html">CUDA
11.4 onwards</a>)</li>
</ul>
<blockquote>
<p>“Devices of compute capability 8.6 have 2x more FP32 operations per
cycle per SM than devices of compute capability 8.0. While a binary
compiled for 8.0 will run as is on 8.6, it is recommended to compile
explicitly for 8.6 to benefit from the increased FP32 throughput.“</p>
<p><strong>https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#improved_fp32</strong></p>
</blockquote>
<h2 id="hopper-cuda-12-and-later"><strong>Hopper (CUDA 12 and
later)</strong></h2>
<ul>
<li><strong>SM90 or <code>SM_90, compute_90</code></strong> –NVIDIA H100
(GH100)</li>
</ul>
<h2
id="市面上常见的商品与版本对应关系">市面上常见的商品与版本对应关系</h2>
<ul>
<li>版本52：Quadro M6000 , GeForce 900, GTX-970, GTX-980, GTX Titan
X</li>
<li>版本53：Tegra (Jetson) TX1 / Tegra X1, Drive CX, Drive PX, Jetson
Nano</li>
<li>版本60：Quadro GP100, Tesla P100, DGX-1 (Generic Pascal)</li>
<li>版本61：GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030 (GP108), GT
1010 (GP108) Titan Xp, Tesla P40, Tesla P4, Discrete GPU on the NVIDIA
Drive PX2</li>
<li>版本62：Integrated GPU on the NVIDIA Drive PX2, Tegra (Jetson)
TX2</li>
<li>版本70：DGX-1 with Volta, Tesla V100, GTX 1180 (GV104), Titan V,
Quadro GV100</li>
<li>版本72：Jetson AGX Xavier, Drive AGX Pegasus, Xavier NX</li>
<li>版本75：GTX/RTX Turing – GTX 1660 Ti, RTX 2060, RTX 2070, RTX 2080,
Titan RTX, Quadro RTX 4000, Quadro RTX 5000, Quadro RTX 6000, Quadro RTX
8000, Quadro T1000/T2000, Tesla T4</li>
<li>版本80：NVIDIA A100 (the name “Tesla” has been dropped – GA100),
NVIDIA DGX-A100</li>
<li>版本86：Tesla GA10x cards, RTX Ampere – RTX 3080, GA102 – RTX 3090,
RTX A2000, A3000, A4000, A5000, A6000, NVIDIA A40, GA106 – RTX 3060,
GA104 – RTX 3070, GA107 – RTX 3050, Quadro A10, Quadro A16, Quadro A40,
A2 Tensor Core GPU</li>
</ul>
]]></content>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>经典多层金字塔锐化(Multi-Level Pyramid Edge Enhancement)</title>
    <url>/2023/10/24/%E7%BB%8F%E5%85%B8%E5%A4%9A%E5%B1%82%E9%87%91%E5%AD%97%E5%A1%94%E9%94%90%E5%8C%96-Multi-Level-Pyramid-Edge-Enhancement/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>锐化方法: 锐化图 = 输入图 + 高频 + 中频 + 低频</p>
<span id="more"></span>
<p>高频部分:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">高频获取方式:   hf = <span class="built_in">gaussblur</span>(input, sigma) - <span class="built_in">gaussblur</span>(input, sigma * band1)</span><br><span class="line">高频进一步增强: hf = <span class="built_in">apply_gamma</span>(hf, gamma_power1)</span><br><span class="line">输入图锐化:     sharpened1 = input + hf * strength1</span><br><span class="line">输入图与锐化图的blending:</span><br><span class="line">	res1 = sharpened1 * weight1 + input * (<span class="number">1</span> - weight1)</span><br><span class="line">	weight1 = <span class="built_in">clamp</span>(std / stdthresh1 + blendbias1, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>中频部分:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">中频获取方式:   mf = <span class="built_in">gaussblur</span>(input, sigma * band1) - <span class="built_in">gaussblur</span>(input, sigma * band1 * band2)</span><br><span class="line">中频进一步增强: mf = <span class="built_in">apply_gamma</span>(mf, gamma_power2)</span><br><span class="line">输入图锐化:     sharpened2 = res1 + mf * strength2</span><br><span class="line">输入图与锐化图的blending:</span><br><span class="line">	res2 = sharpene2 * weight2 + res1 * (<span class="number">1</span> - weight2)</span><br><span class="line">	weight = <span class="built_in">clamp</span>(std / stdthresh2 + blendbias2, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>低频部分:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">低频获取方式:   lf = <span class="built_in">gaussblur</span>(input, sigma * band1 * band2) - <span class="built_in">gaussblur</span>(input, sigma * band1 * band2 * band3)</span><br><span class="line">低频进一步增强: lf = <span class="built_in">apply_gamma</span>(lf, gamma_power3)</span><br><span class="line">输入图锐化:     sharpened3 = res2 + lf * strength3</span><br><span class="line">输入图与锐化图的blending:</span><br><span class="line">	res3 = sharpene3 * weight3 + res2 * (<span class="number">1</span> - weight3)</span><br><span class="line">	weight3 = <span class="built_in">clamp</span>(std / stdthresh3 + blendbias3, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>OpenCV</tag>
        <tag>Sharpening</tag>
        <tag>SR</tag>
      </tags>
  </entry>
  <entry>
    <title>探索C++中的Lambda表达式</title>
    <url>/2023/12/14/%E6%8E%A2%E7%B4%A2C-%E4%B8%AD%E7%9A%84Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>Lambda 表达式是 C++11
引入的一个重要特性，它为函数式编程风格提供了更灵活和便利的方法。本文将探讨
Lambda
表达式的基础知识、语法结构、使用场景以及与传统函数指针和函数对象的比较。</p>
<span id="more"></span>
<h2 id="lambda-表达式的基础知识">Lambda 表达式的基础知识</h2>
<p>Lambda 表达式的基本语法结构，包括捕获列表、参数列表、可选的 mutable
修饰符、返回类型和函数体。</p>
<p>示例：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> lambda = []() &#123; std::cout &lt;&lt; <span class="string">&quot;Hello, Lambda!&quot;</span> &lt;&lt; std::endl; &#125;;</span><br><span class="line"><span class="built_in">lambda</span>(); <span class="comment">// 调用 Lambda 表达式</span></span><br></pre></td></tr></table></figure>
<p>Lambda
表达式捕获外部变量的方式：值捕获、引用捕获、隐式捕获等，并讨论其影响和使用场景。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">auto</span> lambda = [x]() &#123; std::cout &lt;&lt; <span class="string">&quot;Captured value: &quot;</span> &lt;&lt; x &lt;&lt; std::endl; &#125;;</span><br><span class="line"><span class="built_in">lambda</span>(); <span class="comment">// 输出捕获的值 x</span></span><br></pre></td></tr></table></figure>
<p>Lambda
表达式的参数传递和返回类型推导的规则，以及如何显式指定参数类型和返回类型。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> lambda = [](<span class="type">int</span> a, <span class="type">int</span> b) -&gt; <span class="type">int</span> &#123; <span class="keyword">return</span> a + b; &#125;;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Sum: &quot;</span> &lt;&lt; <span class="built_in">lambda</span>(<span class="number">3</span>, <span class="number">4</span>) &lt;&lt; std::endl; <span class="comment">// 输出 7</span></span><br></pre></td></tr></table></figure>
<h2 id="lambda-表达式的使用">Lambda 表达式的使用</h2>
<p>Lambda 表达式在现代 C++ 编程中的常见用法和实际应用场景，如 STL
算法、回调函数、多线程编程等。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>&gt; numbers = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line"><span class="type">int</span> count = std::<span class="built_in">count_if</span>(numbers.<span class="built_in">begin</span>(), numbers.<span class="built_in">end</span>(), [](<span class="type">int</span> x) &#123; <span class="keyword">return</span> x % <span class="number">2</span> == <span class="number">0</span>; &#125;);</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Count of even numbers: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>
<p>对比 Lambda
表达式与传统的函数指针和函数对象的异同点，包括性能、可读性和灵活性等方面的比较。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Lambda 表达式作为回调函数</span></span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt; numbers = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">std::for_each(numbers.<span class="built_in">begin</span>(), numbers.<span class="built_in">end</span>(), [](<span class="type">int</span> x) &#123; std::cout &lt;&lt; x &lt;&lt; std::endl; &#125;);</span><br></pre></td></tr></table></figure>
<h2 id="高级话题和技巧">高级话题和技巧</h2>
<p>Lambda
表达式与其捕获变量之间的关系，涉及变量的生命周期和作用域，以及闭包的概念。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">std::function&lt;<span class="title">int</span><span class="params">(<span class="type">int</span>)</span>&gt; <span class="title">closureExample</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> [x](<span class="type">int</span> y) &#123; <span class="keyword">return</span> x + y; &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> lambda = <span class="built_in">closureExample</span>(<span class="number">5</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Closure result: &quot;</span> &lt;&lt; <span class="built_in">lambda</span>(<span class="number">3</span>) &lt;&lt; std::endl; <span class="comment">// 输出 8</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何在多线程编程中使用 Lambda
表达式，以及如何正确处理共享状态和线程安全性。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; numbers = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    std::mutex mtx;</span><br><span class="line"></span><br><span class="line">    std::for_each(numbers.<span class="built_in">begin</span>(), numbers.<span class="built_in">end</span>(), [&amp;](<span class="type">int</span>&amp; x) &#123;</span><br><span class="line">        std::lock_guard&lt;std::mutex&gt; <span class="built_in">lock</span>(mtx);</span><br><span class="line">        x *= <span class="number">2</span>;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    std::for_each(numbers.<span class="built_in">begin</span>(), numbers.<span class="built_in">end</span>(), [](<span class="type">int</span> x) &#123;</span><br><span class="line">        std::cout &lt;&lt; x &lt;&lt; std::endl; <span class="comment">// 输出修改后的值</span></span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最佳实践和性能优化建议，包括避免过度捕获、使用移动语义、避免引起资源泄漏等。</p>
<p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; vec = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用引用捕获，避免不必要的值捕获</span></span><br><span class="line">    <span class="type">int</span> sum = <span class="number">0</span>;</span><br><span class="line">    std::for_each(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), [&amp;](<span class="type">int</span> x) &#123; sum += x; &#125;);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Sum: &quot;</span> &lt;&lt; sum &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用移动语义，提高性能</span></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; anotherVec = &#123;<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>&#125;;</span><br><span class="line">    std::for_each(anotherVec.<span class="built_in">begin</span>(), anotherVec.<span class="built_in">end</span>(), [vec = std::<span class="built_in">move</span>(vec)](<span class="type">int</span> x) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Moved vector element: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Lambda 表达式为 C++
编程带来了更加灵活和强大的编程手段，通过上述示例的讲解，读者可以更全面地了解和应用
Lambda 表达式。通过 Lambda 表达式，C++
的编程范式也更加现代化和高效化。</p>
]]></content>
  </entry>
  <entry>
    <title>高通平台ISP调试记录(1)-ANR</title>
    <url>/2023/05/07/%E9%AB%98%E9%80%9A%E5%B9%B3%E5%8F%B0ISP%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95-1-ANR/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>anr模块</p>
<span id="more"></span>
<p>enable_grey_treatment_thr_modification</p>
<p>控制开启边缘去彩噪</p>
<p>detect_grey_condition_chromaticity_thr_low</p>
<p>detect_grey_condition_chromaticity_thr_high</p>
<p>detect_grey_condition_y_max_derivative_thr_low</p>
<p>detect_grey_condition_y_max_derivative_thr_high</p>
<p>检测是否需要去彩噪的threshold</p>
<p>thr_modification_target_y</p>
<p>thr_modification_target_u</p>
<p>thr_modification_target_v</p>
<p>检测到需要加强edge false color denois才生效, 值越打越强</p>
<p>luma_filter_lut_thr_y</p>
<p>luma_filter_lut_thr_uv</p>
<p>为了解决lsc导致的噪声，按照半径区分, 值越大去噪越强</p>
<p>chroma_filter_lut_thr_y</p>
<p>chroma_filter_lut_thr_uv</p>
<p>为了解决lsc导致的噪声，按照半径区分, 值越大去噪越强</p>
<p>y_threshold_per_y</p>
<p>u_threshold_per_y</p>
<p>v_threshold_per_y</p>
<p>值越大去噪越强, 最常用</p>
<p>luma_input_indication_thr_modification_scale</p>
<p>chroma_input_indication_thr_modification_scale</p>
<p>full path上不认为是噪声, 但是DC4上需要做去噪, 此时开启inter length,
如果inter length的值为32, 则full path 的threshold就是full path
threshold的2倍</p>
<p>dcblend2_luma_strength_function</p>
<p>dcblend2_chroma_strength_function（0 0 0 0 64 128）融合权重最大值,
去噪最强</p>
<p>一般不动</p>
]]></content>
      <tags>
        <tag>ISP</tag>
      </tags>
  </entry>
  <entry>
    <title>超分辨率Loss设计记录(1)</title>
    <url>/2022/11/19/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87Loss%E8%AE%BE%E8%AE%A1%E8%AE%B0%E5%BD%95-1/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>在超分辨率(Super-Resolution)网络训练中使用均方误差(MSE)损失函数确实存在一个常见问题,
即可能导致生成的结果过于平滑和模糊
这是因为MSE损失函数鼓励模型生成像素值,
以使其与目标图像的像素值之间的平方差最小化这种最小化平方差的方法有时会导致图像细节的丢失,
使得生成的高分辨率图像看起来过于平滑.</p>
<span id="more"></span>
<p><img src="https://s2.loli.net/2023/10/19/WEjclfagntGVxbo.png" /></p>
<p>相关材料可以查看<a
href="https://arxiv.org/pdf/1609.04802v5.pdf">SRGAN</a>中Figure2以及1.1.3小节.
虽然直接优化MSE可以产生较高的PSNR/SSIM, 但是在zoom scale较大的情况下,
MSE作为loss function引导的学习无法使得重建图像捕获细节信息,
从论文Figure2中可以看到, 左二图有较高的PSNR/SSIM, 但是从观感上判断,
左三图明显具有更多的细节.</p>
<p>为了解决这个问题, 通常在超分辨率网络中使用其他损失函数或技术,
以更好地保留细节和纹理 以下是一些替代方法：</p>
<ol type="1">
<li><p><strong>感知损失(Perceptual Loss)</strong>：使用感知损失,
通常是使用预训练的深度卷积神经网络(如VGG)来计算生成图像与目标图像之间的特征表示的差异
这种方法更强调图像的结构和纹理, 而不仅仅是像素值
这有助于生成更具细节和真实感的图像</p></li>
<li><p><strong>对抗性损失(Adversarial
Loss)</strong>：引入生成对抗网络(GAN)的方法,
其中生成器网络和判别器网络相互竞争 生成器的目标是欺骗判别器,
而判别器的目标是区分生成图像和真实图像
这种对抗性训练有助于生成更逼真的图像</p></li>
<li><p><strong>内容和风格损失(Content and Style
Loss)</strong>：结合感知损失和风格损失,
以确保生成的图像在内容和风格上都与目标图像相似</p></li>
<li><p><strong>自适应权重调整</strong>：使用动态权重或损失加权方法,
以平衡不同类型的损失函数,
以便在训练过程中更好地控制平滑度和细节</p></li>
</ol>
<p>这些方法可以帮助超分辨率网络生成更锐利和更具细节的高分辨率图像,
而不仅仅是通过最小化像素级差异来生成图像
选择哪种方法取决于具体的问题和数据集, 以及对生成图像的期望质量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment">#SRGAN使用预训练好的VGG19，用生成器的结果以及原始图像通过VGG后分别得到的特征图计算MSE，具体解释推荐看SRGAN的相关资料</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device</span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        vgg = models.vgg19(<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> pa <span class="keyword">in</span> vgg.parameters():</span><br><span class="line">            pa.requires_grad = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.vgg = vgg.features[:<span class="number">16</span>]</span><br><span class="line">        <span class="variable language_">self</span>.vgg = <span class="variable language_">self</span>.vgg.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = <span class="variable language_">self</span>.vgg(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment">#内容损失</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ContentLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.mse = nn.MSELoss()</span><br><span class="line">        <span class="variable language_">self</span>.vgg19 = VGG(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, fake, real</span>):</span><br><span class="line">        feature_fake = <span class="variable language_">self</span>.vgg19(fake)</span><br><span class="line">        feature_real = <span class="variable language_">self</span>.vgg19(real)</span><br><span class="line">        loss = <span class="variable language_">self</span>.mse(feature_fake, feature_real)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">#对抗损失</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AdversarialLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        loss = torch.<span class="built_in">sum</span>(-torch.log(x))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">#感知损失</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PerceptualLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.vgg_loss = ContentLoss(device)</span><br><span class="line">        <span class="variable language_">self</span>.adversarial = AdversarialLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, fake, real, x</span>):</span><br><span class="line">        vgg_loss = <span class="variable language_">self</span>.vgg_loss(fake, real)</span><br><span class="line">        adversarial_loss = <span class="variable language_">self</span>.adversarial(x)</span><br><span class="line">        <span class="keyword">return</span> vgg_loss + <span class="number">1e-3</span>*adversarial_loss</span><br><span class="line"></span><br><span class="line"><span class="comment">#正则项，需要说明的是，在SRGAN的后续版本的论文中，这个正则项被删除了</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RegularizationLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        a = torch.square(</span><br><span class="line">            x[:, :, :x.shape[<span class="number">2</span>]-<span class="number">1</span>, :x.shape[<span class="number">3</span>]-<span class="number">1</span>] - x[:, :, <span class="number">1</span>:x.shape[<span class="number">2</span>], :x.shape[<span class="number">3</span>]-<span class="number">1</span>]</span><br><span class="line">        )</span><br><span class="line">        b = torch.square(</span><br><span class="line">            x[:, :, :x.shape[<span class="number">2</span>]-<span class="number">1</span>, :x.shape[<span class="number">3</span>]-<span class="number">1</span>] - x[:, :, :x.shape[<span class="number">2</span>]-<span class="number">1</span>, <span class="number">1</span>:x.shape[<span class="number">3</span>]]</span><br><span class="line">        )</span><br><span class="line">        loss = torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(a+b, <span class="number">1.25</span>))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Loss</tag>
        <tag>SR</tag>
      </tags>
  </entry>
  <entry>
    <title>超分辨率效果改善方案记录(1)</title>
    <url>/2023/04/05/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E6%95%88%E6%9E%9C%E6%94%B9%E5%96%84%E6%96%B9%E6%A1%88%E8%AE%B0%E5%BD%95-1/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>在图像处理和计算机视觉中, 上采样(upsampling)是一种常见的操作,
用于将图像从低分辨率扩大到高分辨率.
两种常见的上采样方法是最近邻上采样(Nearest-neighbor
Upsampling)和双线性上采样(Bilinear Upsampling).
它们各自具有不同的特点:</p>
<span id="more"></span>
<ol type="1">
<li><p><strong>最近邻上采样</strong>:
这种方法在上采样过程中选择与原始像素最接近的像素值, 以填充新像素.
它会导致锯齿状的边缘, 因为它不考虑像素之间的平滑过渡,
导致锐利的边缘.</p></li>
<li><p><strong>双线性上采样</strong>: 双线性上采样考虑了周围像素的权重,
以计算新像素的值. 这使得边缘更加平滑,
因为它会对周围像素的值进行线性插值.
这种方法在上采样过程中产生更平滑的图像,
但可能会导致边缘相对于最近邻上采样来说不够锐利.</p></li>
</ol>
<p>将两种上采样方法结合以获得同时锐利和平滑的结果其实有是可能的,
我们称为混合上采样或自适应上采样. 一种常见的方法是使用权重混合两种方法,
以在不同部分的图像上应用它们. 以下是一种简单的方法:</p>
<ol type="1">
<li><p><strong>定义混合权重</strong>:
为了结合最近邻上采样和双线性上采样, 您可以定义一个混合权重图像.
这个权重图像决定了每个像素处应该使用哪种上采样方法的权重.</p></li>
<li><p><strong>应用混合权重</strong>: 使用混合权重图像,
对每个像素应用最近邻上采样和双线性上采样. 具体地, 对于每个像素,
根据混合权重来决定最近邻和双线性上采样两者的权重. 然后,
将两种上采样结果加权相加以生成混合上采样结果.</p></li>
</ol>
<p>这种方法允许您在图像中的不同区域使用不同的上采样方法,
以获得锐利的边缘和平滑的纹理.</p>
<p>当然, 以下是对您描述的过程的更具技术性的表述:</p>
<p><strong>步骤1: </strong> 首先,
将从2x超分辨率模型获得的Y通道图像分别应用nearest
upsample(Y_nn)和bilinear upsample(Y_bi).</p>
<p><strong>步骤2: </strong> 接下来, 通过在Y_nn和Y_bi上执行卷积操作,
生成图像的垂直和水平边缘. 这个步骤有助于增强图像的边缘信息.</p>
<p><strong>步骤3: </strong>
利用OpenCV库的<code>cv::cartToPolar()</code>函数,
计算垂直和水平边缘的tan角度和幅度. 这一步有助于了解边缘的方向和强度.</p>
<p><strong>步骤4: </strong> 创建一个融合mask,
将角度接近0、90和180度的像素设置为1, 同时将幅度小于5的像素设置为0.
这个mask有助于确定需要特定上采样结果的区域.</p>
<p><strong>步骤5: </strong> 对融合mask进行膨胀(dilate)操作,
扩展需要混合结果的区域.
这个膨胀操作确保了最近邻上采样和双线性上采样区域之间的平滑过渡.</p>
<p><strong>步骤6: </strong> 最后, 将融合mask应用于Y_nn和Y_bi的结果,
得到融合的输出Y_out. 融合结果的计算公式为: Y_out = Y_nn * mask + (1.0 -
mask) * Y_bi. 这个过程产生了最终图像, 根据融合mask的区域,
综合了最近邻上采样的锐利度和双线性上采样的平滑度.</p>
<p>这种方法通过考虑边缘细节和不同上采样区域之间的平滑过渡,
确保了改进和平衡的超分辨率结果.</p>
]]></content>
      <tags>
        <tag>SR</tag>
      </tags>
  </entry>
  <entry>
    <title>光追去噪技术深度解析：从理论到实践</title>
    <url>/2025/10/12/%E5%85%89%E8%BF%BD%E5%8E%BB%E5%99%AA/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<h2 id="引言">引言</h2>
<p>光线追踪（Ray
Tracing）作为计算机图形学中的核心技术，能够生成高度逼真的图像效果。然而，由于光线追踪的计算复杂度极高，在实时渲染中往往需要大幅减少采样数量，这导致了严重的噪声问题。光追去噪技术应运而生，通过智能的滤波算法在保持视觉质量的同时显著提升渲染性能。</p>
<p>本文将深入探讨光追去噪的技术原理、主要算法、实现细节以及性能优化策略，为读者提供全面的技术视角。</p>
<h2 id="光追噪声的本质与挑战">1. 光追噪声的本质与挑战</h2>
<h3 id="噪声产生的原因">1.1 噪声产生的原因</h3>
<p>光线追踪中的噪声主要来源于以下几个方面：</p>
<ol type="1">
<li><strong>采样不足</strong>：为了实时性能，每像素的采样数通常限制在1-4个</li>
<li><strong>随机采样</strong>：蒙特卡洛方法引入的随机性</li>
<li><strong>高频细节</strong>：镜面反射、焦散等高频现象需要大量采样</li>
<li><strong>几何复杂性</strong>：复杂场景中的遮挡和反射关系</li>
</ol>
<h3 id="噪声的数学表示">1.2 噪声的数学表示</h3>
<p>对于像素 <span class="math inline">\(i\)</span>，其真实颜色值 <span
class="math inline">\(C_i\)</span> 可以表示为：</p>
<p><span class="math display">\[C_i = \frac{1}{N} \sum_{j=1}^{N} f(x_j,
\omega_j)\]</span></p>
<p>其中 <span class="math inline">\(N\)</span> 是采样数，<span
class="math inline">\(f(x_j, \omega_j)\)</span> 是第 <span
class="math inline">\(j\)</span> 个采样点的辐射度函数。</p>
<p>由于采样不足，我们只能得到噪声估计：</p>
<p><span class="math display">\[\hat{C}_i = \frac{1}{N} \sum_{j=1}^{N}
f(x_j, \omega_j) + \epsilon_i\]</span></p>
<p>其中 <span class="math inline">\(\epsilon_i\)</span> 是噪声项。</p>
<h2 id="主要去噪算法">2. 主要去噪算法</h2>
<h3 id="时空方差引导滤波svgf">2.1 时空方差引导滤波（SVGF）</h3>
<p>SVGF（Spatiotemporal Variance-Guided
Filtering）是目前最成功的实时光追去噪算法之一。</p>
<h4 id="算法原理">2.1.1 算法原理</h4>
<p>SVGF的核心思想是利用时空信息来指导滤波过程：</p>
<ol type="1">
<li><strong>空间滤波</strong>：利用邻域像素的相似性</li>
<li><strong>时间滤波</strong>：利用历史帧信息</li>
<li><strong>方差引导</strong>：根据方差自适应调整滤波强度</li>
</ol>
<h4 id="数学框架">2.1.2 数学框架</h4>
<p>对于像素 <span class="math inline">\(p\)</span>，滤波后的颜色为：</p>
<p><span class="math display">\[C_{filtered}(p) = \frac{\sum_{q \in
\Omega_p} w(p,q) \cdot C(q)}{\sum_{q \in \Omega_p} w(p,q)}\]</span></p>
<p>权重函数定义为：</p>
<p><span class="math display">\[w(p,q) = w_s(p,q) \cdot w_t(p,q) \cdot
w_v(p,q)\]</span></p>
<p>其中： - <span class="math inline">\(w_s(p,q)\)</span> 是空间权重 -
<span class="math inline">\(w_t(p,q)\)</span> 是时间权重<br />
- <span class="math inline">\(w_v(p,q)\)</span> 是方差权重</p>
<h4 id="空间权重">2.1.3 空间权重</h4>
<p>空间权重基于几何和颜色的相似性：</p>
<p><span class="math display">\[w_s(p,q) =
\exp\left(-\frac{||p-q||^2}{2\sigma_s^2}\right) \cdot
\exp\left(-\frac{||C(p)-C(q)||^2}{2\sigma_c^2}\right)\]</span></p>
<h4 id="时间权重">2.1.4 时间权重</h4>
<p>时间权重考虑运动向量和颜色变化：</p>
<p><span class="math display">\[w_t(p,q) = \exp\left(-\frac{||C(p) -
C_{prev}(p + mv)||^2}{2\sigma_t^2}\right)\]</span></p>
<p>其中 <span class="math inline">\(mv\)</span> 是运动向量。</p>
<h3 id="时间抗锯齿taa">2.2 时间抗锯齿（TAA）</h3>
<p>TAA（Temporal Anti-Aliasing）通过累积历史帧信息来减少噪声。</p>
<h4 id="历史累积">2.2.1 历史累积</h4>
<p><span class="math display">\[C_{accum}(p,t) = \alpha \cdot
C_{current}(p,t) + (1-\alpha) \cdot C_{accum}(p,t-1)\]</span></p>
<p>其中 <span class="math inline">\(\alpha\)</span> 是混合系数，通常取
0.1-0.2。</p>
<h4 id="历史拒绝">2.2.2 历史拒绝</h4>
<p>为了避免错误的历史信息，需要检测并拒绝不匹配的历史像素：</p>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> historyWeight = <span class="number">1.0</span>;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">abs</span>(currentColor - historyColor) &gt; threshold) &#123;</span><br><span class="line">    historyWeight = <span class="number">0.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="双边蒙特卡洛滤波bmfr">2.3 双边蒙特卡洛滤波（BMFR）</h3>
<p>BMFR（Bilateral Monte Carlo
Filtering）结合了双边滤波和蒙特卡洛方法。</p>
<h4 id="双边滤波核">2.3.1 双边滤波核</h4>
<p><span class="math display">\[B(p) = \frac{1}{W_p} \sum_{q \in
\Omega_p} f_s(||p-q||) \cdot f_r(||I(p)-I(q)||) \cdot I(q)\]</span></p>
<p>其中： - <span class="math inline">\(f_s\)</span> 是空间核函数 -
<span class="math inline">\(f_r\)</span> 是范围核函数 - <span
class="math inline">\(W_p\)</span> 是归一化因子</p>
<h4 id="自适应采样">2.3.2 自适应采样</h4>
<p>BMFR根据局部方差自适应调整采样数：</p>
<p><span class="math display">\[N_{adaptive}(p) = N_{base} \cdot \max(1,
\frac{\sigma^2(p)}{\sigma_{target}^2})\]</span></p>
<h2 id="高级去噪技术">3. 高级去噪技术</h2>
<h3 id="深度学习去噪">3.1 深度学习去噪</h3>
<h4 id="网络架构">3.1.1 网络架构</h4>
<p>现代深度学习去噪网络通常采用编码器-解码器架构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DenoisingNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">9</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># RGB + Normal + Depth + Albedo</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.decoder = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">3</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        features = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        output = <span class="variable language_">self</span>.decoder(features)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h4 id="损失函数">3.1.2 损失函数</h4>
<p>结合L1损失和感知损失：</p>
<p><span class="math display">\[L_{total} = \lambda_1 L_{L1} + \lambda_2
L_{perceptual} + \lambda_3 L_{temporal}\]</span></p>
<h3 id="自适应采样-1">3.2 自适应采样</h3>
<h4 id="重要性采样">3.2.1 重要性采样</h4>
<p>根据场景复杂度自适应分配采样预算：</p>
<p><span class="math display">\[p(x) \propto
\frac{f(x)}{q(x)}\]</span></p>
<p>其中 <span class="math inline">\(f(x)\)</span> 是目标函数，<span
class="math inline">\(q(x)\)</span> 是重要性分布。</p>
<h4 id="分层采样">3.2.2 分层采样</h4>
<p>将采样空间分层，优先采样高方差区域：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SampleInfo</span> &#123;</span><br><span class="line">    float3 position;</span><br><span class="line">    float3 direction;</span><br><span class="line">    <span class="type">float</span> importance;</span><br><span class="line">    <span class="type">int</span> layer;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">hierarchicalSampling</span><span class="params">(SampleInfo&amp; sample)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 根据重要性选择采样层</span></span><br><span class="line">    <span class="type">int</span> layer = <span class="built_in">selectLayer</span>(sample.importance);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 在选定层内进行采样</span></span><br><span class="line">    sample.position = <span class="built_in">sampleInLayer</span>(layer);</span><br><span class="line">    sample.direction = <span class="built_in">sampleDirection</span>(sample.position);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实现细节与优化">4. 实现细节与优化</h2>
<h3 id="gpu实现优化">4.1 GPU实现优化</h3>
<h4 id="内存访问优化">4.1.1 内存访问优化</h4>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用共享内存减少全局内存访问</span></span><br><span class="line"><span class="keyword">shared</span> float3 sharedColors[<span class="number">16</span>][<span class="number">16</span>];</span><br><span class="line"><span class="keyword">shared</span> <span class="type">float</span> sharedDepths[<span class="number">16</span>][<span class="number">16</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预加载邻域数据</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">16</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">16</span>; j++) &#123;</span><br><span class="line">        int2 coord = threadID.xy + int2(i<span class="number">-8</span>, j<span class="number">-8</span>);</span><br><span class="line">        sharedColors[i][j] = tex2D(colorTexture, coord);</span><br><span class="line">        sharedDepths[i][j] = tex2D(depthTexture, coord);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="计算优化">4.1.2 计算优化</h4>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用快速指数近似</span></span><br><span class="line"><span class="type">float</span> fastExp(<span class="type">float</span> x) &#123;</span><br><span class="line">    x = <span class="number">1.0</span> + x / <span class="number">256.0</span>;</span><br><span class="line">    x *= x; x *= x; x *= x; x *= x;</span><br><span class="line">    x *= x; x *= x; x *= x; x *= x;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优化的权重计算</span></span><br><span class="line"><span class="type">float</span> computeWeight(float3 color1, float3 color2, <span class="type">float</span> depth1, <span class="type">float</span> depth2) &#123;</span><br><span class="line">    <span class="type">float</span> colorDiff = <span class="built_in">dot</span>(color1 - color2, color1 - color2);</span><br><span class="line">    <span class="type">float</span> depthDiff = <span class="built_in">abs</span>(depth1 - depth2);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> fastExp(-colorDiff * colorWeight - depthDiff * depthWeight);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="多分辨率处理">4.2 多分辨率处理</h3>
<h4 id="金字塔分解">4.2.1 金字塔分解</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ImagePyramid</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;Texture2D&gt; levels;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">buildPyramid</span><span class="params">(Texture2D&amp; input)</span> </span>&#123;</span><br><span class="line">        levels.<span class="built_in">clear</span>();</span><br><span class="line">        levels.<span class="built_in">push_back</span>(input);</span><br><span class="line">        </span><br><span class="line">        Texture2D current = input;</span><br><span class="line">        <span class="keyword">while</span> (current.width &gt; <span class="number">1</span> &amp;&amp; current.height &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            Texture2D downsampled = <span class="built_in">downsample</span>(current);</span><br><span class="line">            levels.<span class="built_in">push_back</span>(downsampled);</span><br><span class="line">            current = downsampled;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">Texture2D <span class="title">downsample</span><span class="params">(Texture2D&amp; input)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 使用高斯滤波进行下采样</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">gaussianDownsample</span>(input, <span class="number">0.5f</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="多尺度滤波">4.2.2 多尺度滤波</h4>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line">float3 multiScaleFilter(float2 uv) &#123;</span><br><span class="line">    float3 result = float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="type">float</span> totalWeight = <span class="number">0.0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 在不同尺度上进行滤波</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> scale = <span class="number">0</span>; scale &lt; numScales; scale++) &#123;</span><br><span class="line">        <span class="type">float</span> scaleFactor = <span class="built_in">pow</span>(<span class="number">2.0</span>, scale);</span><br><span class="line">        float3 filtered = filterAtScale(uv, scaleFactor);</span><br><span class="line">        <span class="type">float</span> weight = computeScaleWeight(scale);</span><br><span class="line">        </span><br><span class="line">        result += filtered * weight;</span><br><span class="line">        totalWeight += weight;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result / totalWeight;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="性能分析与调优">5. 性能分析与调优</h2>
<h3 id="性能瓶颈分析">5.1 性能瓶颈分析</h3>
<h4 id="内存带宽">5.1.1 内存带宽</h4>
<p>光追去噪的主要瓶颈通常是内存带宽：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 内存带宽计算</span></span><br><span class="line"><span class="type">float</span> memoryBandwidth = (width * height * channels * <span class="built_in">sizeof</span>(<span class="type">float</span>)) / renderTime;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优化策略</span></span><br><span class="line"><span class="comment">// 1. 使用纹理压缩</span></span><br><span class="line"><span class="comment">// 2. 减少中间缓冲区</span></span><br><span class="line"><span class="comment">// 3. 优化内存访问模式</span></span><br></pre></td></tr></table></figure>
<h4 id="计算复杂度">5.1.2 计算复杂度</h4>
<p>滤波算法的复杂度分析：</p>
<ul>
<li><strong>空间滤波</strong>：<span class="math inline">\(O(N \cdot
K^2)\)</span>，其中 <span class="math inline">\(N\)</span>
是像素数，<span class="math inline">\(K\)</span> 是核大小</li>
<li><strong>时间滤波</strong>：<span
class="math inline">\(O(N)\)</span></li>
<li><strong>方差计算</strong>：<span class="math inline">\(O(N \cdot
K^2)\)</span></li>
</ul>
<h3 id="自适应优化">5.2 自适应优化</h3>
<h4 id="动态核大小">5.2.1 动态核大小</h4>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> computeKernelSize(<span class="type">float</span> variance) &#123;</span><br><span class="line">    <span class="comment">// 根据方差动态调整核大小</span></span><br><span class="line">    <span class="keyword">if</span> (variance &gt; highVarianceThreshold) &#123;</span><br><span class="line">        <span class="keyword">return</span> largeKernelSize;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (variance &gt; mediumVarianceThreshold) &#123;</span><br><span class="line">        <span class="keyword">return</span> mediumKernelSize;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> smallKernelSize;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="质量-性能平衡">5.2.2 质量-性能平衡</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">QualitySettings</span> &#123;</span><br><span class="line">    <span class="type">float</span> temporalWeight;</span><br><span class="line">    <span class="type">float</span> spatialWeight;</span><br><span class="line">    <span class="type">int</span> kernelSize;</span><br><span class="line">    <span class="type">int</span> numSamples;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">QualitySettings <span class="title">adaptiveQuality</span><span class="params">(<span class="type">float</span> targetFPS, <span class="type">float</span> currentFPS)</span> </span>&#123;</span><br><span class="line">    QualitySettings settings;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (currentFPS &lt; targetFPS * <span class="number">0.9f</span>) &#123;</span><br><span class="line">        <span class="comment">// 性能不足，降低质量</span></span><br><span class="line">        settings.temporalWeight *= <span class="number">0.8f</span>;</span><br><span class="line">        settings.kernelSize = <span class="built_in">max</span>(<span class="number">3</span>, settings.kernelSize - <span class="number">2</span>);</span><br><span class="line">        settings.numSamples = <span class="built_in">max</span>(<span class="number">1</span>, settings.numSamples - <span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (currentFPS &gt; targetFPS * <span class="number">1.1f</span>) &#123;</span><br><span class="line">        <span class="comment">// 性能充足，提升质量</span></span><br><span class="line">        settings.temporalWeight = <span class="built_in">min</span>(<span class="number">1.0f</span>, settings.temporalWeight * <span class="number">1.1f</span>);</span><br><span class="line">        settings.kernelSize = <span class="built_in">min</span>(<span class="number">15</span>, settings.kernelSize + <span class="number">2</span>);</span><br><span class="line">        settings.numSamples = <span class="built_in">min</span>(<span class="number">8</span>, settings.numSamples + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> settings;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实际应用案例">6. 实际应用案例</h2>
<h3 id="游戏引擎集成">6.1 游戏引擎集成</h3>
<h4 id="unity集成">6.1.1 Unity集成</h4>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">RayTracingDenoiser</span> : <span class="title">MonoBehaviour</span> &#123;</span><br><span class="line">    [<span class="meta">SerializeField</span>] <span class="keyword">private</span> ComputeShader denoiseShader;</span><br><span class="line">    [<span class="meta">SerializeField</span>] <span class="keyword">private</span> RenderTexture noisyTexture;</span><br><span class="line">    [<span class="meta">SerializeField</span>] <span class="keyword">private</span> RenderTexture denoisedTexture;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">Update</span>()</span> &#123;</span><br><span class="line">        <span class="comment">// 设置计算着色器参数</span></span><br><span class="line">        denoiseShader.SetTexture(<span class="number">0</span>, <span class="string">&quot;NoisyTexture&quot;</span>, noisyTexture);</span><br><span class="line">        denoiseShader.SetTexture(<span class="number">0</span>, <span class="string">&quot;DenoisedTexture&quot;</span>, denoisedTexture);</span><br><span class="line">        denoiseShader.SetFloat(<span class="string">&quot;Time&quot;</span>, Time.time);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 执行去噪</span></span><br><span class="line">        <span class="built_in">int</span> threadGroupsX = Mathf.CeilToInt(Screen.width / <span class="number">8.0f</span>);</span><br><span class="line">        <span class="built_in">int</span> threadGroupsY = Mathf.CeilToInt(Screen.height / <span class="number">8.0f</span>);</span><br><span class="line">        denoiseShader.Dispatch(<span class="number">0</span>, threadGroupsX, threadGroupsY, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="unreal-engine集成">6.1.2 Unreal Engine集成</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RAYTRACINGDENOISER_API</span> FRayTracingDenoiserModule : <span class="keyword">public</span> IModuleInterface &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">StartupModule</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ShutdownModule</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">RegisterDenoiser</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">UnregisterDenoiser</span><span class="params">()</span></span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TSharedPtr&lt;<span class="keyword">class</span> <span class="title class_">FRayTracingDenoiser</span>&gt; Denoiser;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义去噪器实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FRayTracingDenoiser</span> : <span class="keyword">public</span> IScreenSpaceDenoiser &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Denoise</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        FRDGBuilder&amp; GraphBuilder,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> FViewInfo&amp; View,</span></span></span><br><span class="line"><span class="params"><span class="function">        FRDGTextureRef InputTexture,</span></span></span><br><span class="line"><span class="params"><span class="function">        FRDGTextureRef OutputTexture</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> <span class="keyword">override</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="工业渲染应用">6.2 工业渲染应用</h3>
<h4 id="建筑可视化">6.2.1 建筑可视化</h4>
<p>在建筑可视化中，光追去噪需要处理：</p>
<ol type="1">
<li><strong>复杂几何</strong>：建筑细节和装饰</li>
<li><strong>材质多样性</strong>：玻璃、金属、石材等</li>
<li><strong>光照复杂性</strong>：室内外混合光照</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ArchitecturalDenoiser</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">MaterialInfo</span> &#123;</span><br><span class="line">        <span class="type">float</span> roughness;</span><br><span class="line">        <span class="type">float</span> metallic;</span><br><span class="line">        float3 albedo;</span><br><span class="line">        float3 normal;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">float3 <span class="title">denoiseArchitectural</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        float2 uv,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 color,</span></span></span><br><span class="line"><span class="params"><span class="function">        MaterialInfo material,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 worldPos,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 viewDir</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 根据材质特性调整滤波参数</span></span><br><span class="line">        <span class="type">float</span> materialWeight = <span class="built_in">computeMaterialWeight</span>(material);</span><br><span class="line">        <span class="type">float</span> geometricWeight = <span class="built_in">computeGeometricWeight</span>(worldPos, viewDir);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">adaptiveFilter</span>(color, materialWeight, geometricWeight);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="未来发展趋势">7. 未来发展趋势</h2>
<h3 id="硬件加速">7.1 硬件加速</h3>
<h4 id="专用硬件">7.1.1 专用硬件</h4>
<ul>
<li><strong>RT Core</strong>：NVIDIA的专用光线追踪硬件</li>
<li><strong>AI加速器</strong>：用于深度学习去噪的专用芯片</li>
<li><strong>可编程硬件</strong>：FPGA和ASIC的定制化解决方案</li>
</ul>
<h4 id="并行计算架构">7.1.2 并行计算架构</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 利用GPU的并行计算能力</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ParallelDenoiser</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">denoiseParallel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> std::vector&lt;float3&gt;&amp; input,</span></span></span><br><span class="line"><span class="params"><span class="function">        std::vector&lt;float3&gt;&amp; output,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> numThreads</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> </span>&#123;</span><br><span class="line">        std::vector&lt;std::thread&gt; threads;</span><br><span class="line">        <span class="type">int</span> chunkSize = input.<span class="built_in">size</span>() / numThreads;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numThreads; i++) &#123;</span><br><span class="line">            <span class="type">int</span> start = i * chunkSize;</span><br><span class="line">            <span class="type">int</span> end = (i == numThreads - <span class="number">1</span>) ? input.<span class="built_in">size</span>() : (i + <span class="number">1</span>) * chunkSize;</span><br><span class="line">            </span><br><span class="line">            threads.<span class="built_in">emplace_back</span>([&amp;, start, end]() &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> j = start; j &lt; end; j++) &#123;</span><br><span class="line">                    output[j] = <span class="built_in">denoisePixel</span>(input[j], j);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; thread : threads) &#123;</span><br><span class="line">            thread.<span class="built_in">join</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="算法创新">7.2 算法创新</h3>
<h4 id="神经辐射场nerf">7.2.1 神经辐射场（NeRF）</h4>
<p>结合NeRF技术的新型去噪方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NeRFDenoiser</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.nerf_network = NeRFNetwork()</span><br><span class="line">        <span class="variable language_">self</span>.denoise_network = DenoiseNetwork()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, rays, noisy_colors</span>):</span><br><span class="line">        <span class="comment"># 使用NeRF预测几何信息</span></span><br><span class="line">        geometry_features = <span class="variable language_">self</span>.nerf_network(rays)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结合几何信息进行去噪</span></span><br><span class="line">        denoised_colors = <span class="variable language_">self</span>.denoise_network(</span><br><span class="line">            torch.cat([noisy_colors, geometry_features], dim=-<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> denoised_colors</span><br></pre></td></tr></table></figure>
<h4 id="物理约束去噪">7.2.2 物理约束去噪</h4>
<p>利用物理约束提升去噪质量：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PhysicsConstrainedDenoiser</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">float3 <span class="title">denoiseWithPhysics</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 noisyColor,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 worldPos,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 normal,</span></span></span><br><span class="line"><span class="params"><span class="function">        float3 viewDir,</span></span></span><br><span class="line"><span class="params"><span class="function">        MaterialProperties material</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 计算物理约束</span></span><br><span class="line">        float3 radiance = <span class="built_in">computeRadiance</span>(worldPos, normal, viewDir, material);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在物理约束下进行去噪</span></span><br><span class="line">        float3 denoisedColor = <span class="built_in">physicsAwareFilter</span>(noisyColor, radiance);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 验证物理一致性</span></span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">isPhysicallyConsistent</span>(denoisedColor, material)) &#123;</span><br><span class="line">            denoisedColor = radiance; <span class="comment">// 回退到物理预测</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> denoisedColor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="总结与展望">8. 总结与展望</h2>
<p>光追去噪技术作为实时渲染的关键技术，在过去的几年中取得了显著进展。从传统的滤波方法到现代的深度学习技术，从简单的空间滤波到复杂的时空自适应算法，这一领域正在快速发展。</p>
<h3 id="技术总结">8.1 技术总结</h3>
<ol type="1">
<li><strong>算法成熟度</strong>：SVGF、TAA等算法已经相当成熟，在商业引擎中得到广泛应用</li>
<li><strong>硬件支持</strong>：RT
Core等专用硬件的出现为光追去噪提供了强大的计算基础</li>
<li><strong>深度学习</strong>：AI技术在去噪领域的应用展现出巨大潜力</li>
<li><strong>性能优化</strong>：各种优化技术使得实时去噪成为可能</li>
</ol>
<h3 id="未来挑战">8.2 未来挑战</h3>
<ol type="1">
<li><strong>质量与性能平衡</strong>：如何在保持视觉质量的同时进一步提升性能</li>
<li><strong>复杂场景处理</strong>：如何处理极端复杂的几何和光照条件</li>
<li><strong>动态场景适应</strong>：如何更好地处理快速变化的场景内容</li>
<li><strong>跨平台兼容性</strong>：如何在不同硬件平台上实现一致的性能表现</li>
</ol>
<h3 id="发展方向">8.3 发展方向</h3>
<ol type="1">
<li><strong>端到端优化</strong>：从采样到去噪的全流程优化</li>
<li><strong>自适应算法</strong>：根据场景内容自动调整算法参数</li>
<li><strong>多模态融合</strong>：结合多种信息源提升去噪质量</li>
<li><strong>实时学习</strong>：在运行时学习和适应场景特性</li>
</ol>
<p>光追去噪技术将继续在实时渲染领域发挥重要作用，随着硬件技术的进步和算法的不断创新，我们有理由相信这一技术将带来更加逼真和流畅的视觉体验。</p>
<hr />
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>Schied, C., et al. "Spatiotemporal variance-guided filtering:
real-time reconstruction for path-traced global illumination." <em>High
Performance Graphics</em>. 2017.</li>
<li>Karis, B. "High-quality temporal supersampling." <em>Advances in
Real-Time Rendering in Games, SIGGRAPH Courses</em>. 2014.</li>
<li>Bitterli, B., et al. "Reversible jump metropolis light transport
using inverse mappings." <em>ACM Transactions on Graphics</em>.
2020.</li>
<li>Rousselle, F., et al. "Robust denoising using feature and color
information." <em>Computer Graphics Forum</em>. 2013.</li>
<li>Chaitanya, C. R. A., et al. "Interactive reconstruction of Monte
Carlo image sequences using a recurrent denoising autoencoder." <em>ACM
Transactions on Graphics</em>. 2017.</li>
</ol>
<hr />
<p><em>本文深入探讨了光追去噪技术的各个方面，从理论基础到实际应用，从传统算法到现代创新，为读者提供了全面的技术视角。希望这篇文章能够帮助读者更好地理解和应用光追去噪技术。</em></p>
]]></content>
      <tags>
        <tag>Ray-Tracing</tag>
        <tag>Denoising</tag>
        <tag>Real-time-Rendering</tag>
        <tag>Computer-Graphics</tag>
        <tag>GPU-Computing</tag>
      </tags>
  </entry>
  <entry>
    <title>高通平台ISP调试记录(2)-ASF</title>
    <url>/2023/06/12/%E9%AB%98%E9%80%9A%E5%B9%B3%E5%8F%B0ISP%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95-2-ASF/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />
<p>asf模块：</p>
<span id="more"></span>
<p>negative_thr</p>
<p>值越小 -&gt; 黑边越小</p>
<p>layer_1_gain_positive_lut</p>
<p>layer_1_gain_negative_lut</p>
<p>按照亮度分为64个点, 越大锐化越强</p>
<p>layer_1_gain_contrast_positive_lut</p>
<p>layer_1_gain_contrast_negative_lut</p>
<p>8450平台后亮度区分, 越大锐化越强</p>
<p>layer_1_gain_weight_lut</p>
<p>不是细节, 但是也不是平坦区, 值越大锐化越强</p>
<p>layer_1_clamp_ul</p>
<p>layer_1_clamp_ll</p>
<p>值为0, 约等于关闭asf, 主观上控制黑白边</p>
<p>edge_thr</p>
<p>控制detect edge的大小, 值越大, detect的范围越小, edge越少</p>
<p>layer_1_positive_texture_preserve_factor</p>
<p>layer_1_negtive_texture_preserve_factor</p>
<p>控制还原一下儿positve和negtive的细节</p>
<p>layer_1_sp</p>
<p>radial_activity_adj</p>
<p>值越小, 锐化越弱</p>
<p>radial_gain_adj</p>
<p>值越小, 锐化越弱</p>
]]></content>
      <tags>
        <tag>ISP</tag>
      </tags>
  </entry>
</search>
